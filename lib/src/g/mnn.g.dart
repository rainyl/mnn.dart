// coverage:ignore-file
// Copyright (c) 2025, rainyl.  Please see the AUTHORS file
// for details. All rights reserved. Use of this source code is governed by a
// BSD-style license that can be found in the LICENSE file.

// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
// ignore_for_file: type=lint, unused_import
@ffi.DefaultAsset('package:mnn/mnn.dart')
library;

import 'dart:ffi' as ffi;
import '' as self;

/// @brief Creates a new auto timer instance
/// @param line Source code line number (for debugging)
/// @param func Function name (for debugging)
/// @return Pointer to the newly created auto timer
@ffi.Native<mnn_auto_time_t Function(ffi.Int, ffi.Pointer<ffi.Char>)>()
external mnn_auto_time_t mnn_auto_time_create(
  int line,
  ffi.Pointer<ffi.Char> func,
);

/// @brief Destroys an auto timer instance
/// @param auto_time Auto timer instance to destroy
@ffi.Native<ffi.Void Function(mnn_auto_time_t)>()
external void mnn_auto_time_destroy(
  mnn_auto_time_t auto_time,
);

@ffi.Native<
  ffi.UnsignedInt Function(
    mnn_cv_image_process_t,
    ffi.Pointer<ffi.Uint8>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    mnn_tensor_t,
  )
>(symbol: 'mnn_cv_image_process_convert')
external int _mnn_cv_image_process_convert(
  mnn_cv_image_process_t self$1,
  ffi.Pointer<ffi.Uint8> src,
  int iw,
  int ih,
  int stride,
  mnn_tensor_t dest,
);

ErrorCode mnn_cv_image_process_convert(
  mnn_cv_image_process_t self$1,
  ffi.Pointer<ffi.Uint8> src,
  int iw,
  int ih,
  int stride,
  mnn_tensor_t dest,
) => ErrorCode.fromValue(
  _mnn_cv_image_process_convert(
    self$1,
    src,
    iw,
    ih,
    stride,
    dest,
  ),
);

@ffi.Native<
  ffi.UnsignedInt Function(
    mnn_cv_image_process_t,
    ffi.Pointer<ffi.Uint8>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Pointer<ffi.Void>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    halide_type_c_t,
  )
>(symbol: 'mnn_cv_image_process_convert_1')
external int _mnn_cv_image_process_convert_1(
  mnn_cv_image_process_t self$1,
  ffi.Pointer<ffi.Uint8> src,
  int iw,
  int ih,
  int stride,
  ffi.Pointer<ffi.Void> dst,
  int ow,
  int oh,
  int outputBpp,
  int outputStride,
  halide_type_c_t type,
);

ErrorCode mnn_cv_image_process_convert_1(
  mnn_cv_image_process_t self$1,
  ffi.Pointer<ffi.Uint8> src,
  int iw,
  int ih,
  int stride,
  ffi.Pointer<ffi.Void> dst,
  int ow,
  int oh,
  int outputBpp,
  int outputStride,
  halide_type_c_t type,
) => ErrorCode.fromValue(
  _mnn_cv_image_process_convert_1(
    self$1,
    src,
    iw,
    ih,
    stride,
    dst,
    ow,
    oh,
    outputBpp,
    outputStride,
    type,
  ),
);

/// /////////////// ImageProcess //////////////////////////
@ffi.Native<
  mnn_cv_image_process_t Function(
    ffi.Int,
    ffi.Int,
    ffi.Pointer<ffi.Float>,
    ffi.Int,
    ffi.Pointer<ffi.Float>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    mnn_tensor_t,
  )
>()
external mnn_cv_image_process_t mnn_cv_image_process_create(
  int sourceFormat,
  int destFormat,
  ffi.Pointer<ffi.Float> means,
  int mean_count,
  ffi.Pointer<ffi.Float> normals,
  int normal_count,
  int filterType,
  int wrap,
  mnn_tensor_t dst_tensor,
);

@ffi.Native<mnn_tensor_t Function(halide_type_c_t, ffi.Int, ffi.Int, ffi.Int, ffi.Pointer<ffi.Void>)>()
external mnn_tensor_t mnn_cv_image_process_create_image_tensor(
  halide_type_c_t type,
  int width,
  int height,
  int bytes_per_channel,
  ffi.Pointer<ffi.Void> p,
);

@ffi.Native<mnn_cv_image_process_t Function(mnn_image_process_config_t, mnn_tensor_t)>()
external mnn_cv_image_process_t mnn_cv_image_process_create_with_config(
  mnn_image_process_config_t config,
  mnn_tensor_t dst_tensor,
);

@ffi.Native<ffi.Void Function(mnn_cv_image_process_t)>()
external void mnn_cv_image_process_destroy(
  mnn_cv_image_process_t self$1,
);

@ffi.Native<
  ffi.Void Function(
    mnn_cv_image_process_t,
    ffi.Pointer<ffi.Uint8>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
    ffi.Pointer<ffi.Uint8>,
  )
>()
external void mnn_cv_image_process_draw(
  mnn_cv_image_process_t self$1,
  ffi.Pointer<ffi.Uint8> img,
  int w,
  int h,
  int c,
  ffi.Pointer<ffi.Int> regions,
  int num,
  ffi.Pointer<ffi.Uint8> color,
);

/// Matrix operations for ImageProcess
@ffi.Native<mnn_cv_matrix_t Function(mnn_cv_image_process_t)>()
external mnn_cv_matrix_t mnn_cv_image_process_get_matrix(
  mnn_cv_image_process_t self$1,
);

@ffi.Native<ffi.Void Function(mnn_cv_image_process_t)>()
external void mnn_cv_image_process_set_draw(
  mnn_cv_image_process_t self$1,
);

@ffi.Native<ffi.UnsignedInt Function(mnn_cv_image_process_t, mnn_cv_matrix_t)>(
  symbol: 'mnn_cv_image_process_set_matrix',
)
external int _mnn_cv_image_process_set_matrix(
  mnn_cv_image_process_t self$1,
  mnn_cv_matrix_t matrix,
);

ErrorCode mnn_cv_image_process_set_matrix(
  mnn_cv_image_process_t self$1,
  mnn_cv_matrix_t matrix,
) => ErrorCode.fromValue(
  _mnn_cv_image_process_set_matrix(
    self$1,
    matrix,
  ),
);

@ffi.Native<ffi.Void Function(mnn_cv_image_process_t, ffi.Uint8)>()
external void mnn_cv_image_process_set_padding(
  mnn_cv_image_process_t self$1,
  int value,
);

@ffi.Native<ffi.Bool Function(mnn_cv_matrix_t, mnn_cv_matrix_t)>()
external bool mnn_cv_matrix_cheap_equal_to(
  mnn_cv_matrix_t self$1,
  mnn_cv_matrix_t other,
);

/// Matrix operations
@ffi.Native<mnn_cv_matrix_t Function()>()
external mnn_cv_matrix_t mnn_cv_matrix_create();

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t)>()
external void mnn_cv_matrix_destroy(
  mnn_cv_matrix_t self$1,
);

/// MNN_C_API float mnn_cv_matrix_get_min_scale(mnn_cv_matrix_t self);
/// MNN_C_API float mnn_cv_matrix_get_max_scale(mnn_cv_matrix_t self);
@ffi.Native<ffi.Void Function(mnn_cv_matrix_t)>()
external void mnn_cv_matrix_dirty_matrix_type_cache(
  mnn_cv_matrix_t self$1,
);

/// Matrix getters
@ffi.Native<ffi.Float Function(mnn_cv_matrix_t, ffi.Int)>()
external double mnn_cv_matrix_get(
  mnn_cv_matrix_t self$1,
  int index,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Pointer<ffi.Float>)>()
external void mnn_cv_matrix_get9(
  mnn_cv_matrix_t self$1,
  ffi.Pointer<ffi.Float> m,
);

/// Matrix type masks
@ffi.Native<ffi.Int Function(mnn_cv_matrix_t)>()
external int mnn_cv_matrix_get_type(
  mnn_cv_matrix_t self$1,
);

@ffi.Native<ffi.Bool Function(mnn_cv_matrix_t, mnn_cv_matrix_t)>()
external bool mnn_cv_matrix_invert(
  mnn_cv_matrix_t self$1,
  mnn_cv_matrix_t dst,
);

@ffi.Native<ffi.Bool Function(mnn_cv_matrix_t)>()
external bool mnn_cv_matrix_is_identity(
  mnn_cv_matrix_t self$1,
);

@ffi.Native<ffi.Bool Function(mnn_cv_matrix_t)>()
external bool mnn_cv_matrix_is_scale_translate(
  mnn_cv_matrix_t self$1,
);

@ffi.Native<ffi.Bool Function(mnn_cv_matrix_t)>()
external bool mnn_cv_matrix_is_translate(
  mnn_cv_matrix_t self$1,
);

@ffi.Native<
  ffi.Bool Function(mnn_cv_matrix_t, ffi.Pointer<mnn_cv_point_t>, ffi.Pointer<mnn_cv_point_t>, ffi.Int)
>()
external bool mnn_cv_matrix_map_points(
  mnn_cv_matrix_t self$1,
  ffi.Pointer<mnn_cv_point_t> dst,
  ffi.Pointer<mnn_cv_point_t> src,
  int count,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Pointer<mnn_cv_point_t>, ffi.Int)>()
external void mnn_cv_matrix_map_points_inplace(
  mnn_cv_matrix_t self$1,
  ffi.Pointer<mnn_cv_point_t> points,
  int count,
);

@ffi.Native<ffi.Bool Function(mnn_cv_matrix_t, ffi.Pointer<mnn_cv_rect_t>, ffi.Pointer<mnn_cv_rect_t>)>()
external bool mnn_cv_matrix_map_rect(
  mnn_cv_matrix_t self$1,
  ffi.Pointer<mnn_cv_rect_t> dst,
  ffi.Pointer<mnn_cv_rect_t> src,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Pointer<mnn_cv_rect_t>, ffi.Pointer<mnn_cv_rect_t>)>()
external void mnn_cv_matrix_map_rect_scale_translate(
  mnn_cv_matrix_t self$1,
  ffi.Pointer<mnn_cv_rect_t> dst,
  ffi.Pointer<mnn_cv_rect_t> src,
);

@ffi.Native<
  ffi.Void Function(mnn_cv_matrix_t, ffi.Float, ffi.Float, ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Float>)
>()
external void mnn_cv_matrix_map_xy(
  mnn_cv_matrix_t self$1,
  double x,
  double y,
  ffi.Pointer<ffi.Float> mapped_x,
  ffi.Pointer<ffi.Float> mapped_y,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, mnn_cv_matrix_t)>()
external void mnn_cv_matrix_post_concat(
  mnn_cv_matrix_t self$1,
  mnn_cv_matrix_t other,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Int, ffi.Int)>()
external void mnn_cv_matrix_post_idiv(
  mnn_cv_matrix_t self$1,
  int divx,
  int divy,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Float, ffi.Float, ffi.Float)>()
external void mnn_cv_matrix_post_rotate(
  mnn_cv_matrix_t self$1,
  double degrees,
  double px,
  double py,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Float, ffi.Float, ffi.Float, ffi.Float)>()
external void mnn_cv_matrix_post_scale(
  mnn_cv_matrix_t self$1,
  double sx,
  double sy,
  double px,
  double py,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Float, ffi.Float, ffi.Float, ffi.Float)>()
external void mnn_cv_matrix_post_skew(
  mnn_cv_matrix_t self$1,
  double kx,
  double ky,
  double px,
  double py,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Float, ffi.Float)>()
external void mnn_cv_matrix_post_translate(
  mnn_cv_matrix_t self$1,
  double dx,
  double dy,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, mnn_cv_matrix_t)>()
external void mnn_cv_matrix_pre_concat(
  mnn_cv_matrix_t self$1,
  mnn_cv_matrix_t other,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Float, ffi.Float, ffi.Float)>()
external void mnn_cv_matrix_pre_rotate(
  mnn_cv_matrix_t self$1,
  double degrees,
  double px,
  double py,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Float, ffi.Float, ffi.Float, ffi.Float)>()
external void mnn_cv_matrix_pre_scale(
  mnn_cv_matrix_t self$1,
  double sx,
  double sy,
  double px,
  double py,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Float, ffi.Float, ffi.Float, ffi.Float)>()
external void mnn_cv_matrix_pre_skew(
  mnn_cv_matrix_t self$1,
  double kx,
  double ky,
  double px,
  double py,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Float, ffi.Float)>()
external void mnn_cv_matrix_pre_translate(
  mnn_cv_matrix_t self$1,
  double dx,
  double dy,
);

@ffi.Native<ffi.Bool Function(mnn_cv_matrix_t)>()
external bool mnn_cv_matrix_rect_stays_rect(
  mnn_cv_matrix_t self$1,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t)>()
external void mnn_cv_matrix_reset(
  mnn_cv_matrix_t self$1,
);

/// Matrix setters
@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Int, ffi.Float)>()
external void mnn_cv_matrix_set(
  mnn_cv_matrix_t self$1,
  int index,
  double value,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Pointer<ffi.Float>)>()
external void mnn_cv_matrix_set9(
  mnn_cv_matrix_t self$1,
  ffi.Pointer<ffi.Float> m,
);

@ffi.Native<
  ffi.Void Function(
    mnn_cv_matrix_t,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
  )
>()
external void mnn_cv_matrix_set_all(
  mnn_cv_matrix_t self$1,
  double scaleX,
  double skewX,
  double transX,
  double skewY,
  double scaleY,
  double transY,
  double pers0,
  double pers1,
  double pers2,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, mnn_cv_matrix_t, mnn_cv_matrix_t)>()
external void mnn_cv_matrix_set_concat(
  mnn_cv_matrix_t self$1,
  mnn_cv_matrix_t a,
  mnn_cv_matrix_t b,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t)>()
external void mnn_cv_matrix_set_identity(
  mnn_cv_matrix_t self$1,
);

@ffi.Native<
  ffi.Bool Function(mnn_cv_matrix_t, ffi.Pointer<mnn_cv_point_t>, ffi.Pointer<mnn_cv_point_t>, ffi.Int)
>()
external bool mnn_cv_matrix_set_poly_to_poly(
  mnn_cv_matrix_t self$1,
  ffi.Pointer<mnn_cv_point_t> src,
  ffi.Pointer<mnn_cv_point_t> dst,
  int count,
);

@ffi.Native<ffi.Bool Function(mnn_cv_matrix_t, mnn_cv_rect_t, mnn_cv_rect_t, ffi.Int)>()
external bool mnn_cv_matrix_set_rect_to_rect(
  mnn_cv_matrix_t self$1,
  mnn_cv_rect_t src,
  mnn_cv_rect_t dst,
  int scale_to_fit,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Float, ffi.Float, ffi.Float)>()
external void mnn_cv_matrix_set_rotate(
  mnn_cv_matrix_t self$1,
  double degrees,
  double px,
  double py,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Float, ffi.Float, ffi.Float, ffi.Float)>()
external void mnn_cv_matrix_set_scale(
  mnn_cv_matrix_t self$1,
  double sx,
  double sy,
  double px,
  double py,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Float, ffi.Float, ffi.Float, ffi.Float)>()
external void mnn_cv_matrix_set_scale_translate(
  mnn_cv_matrix_t self$1,
  double sx,
  double sy,
  double tx,
  double ty,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Float, ffi.Float, ffi.Float, ffi.Float)>()
external void mnn_cv_matrix_set_sincos(
  mnn_cv_matrix_t self$1,
  double sin,
  double cos,
  double px,
  double py,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Float, ffi.Float, ffi.Float, ffi.Float)>()
external void mnn_cv_matrix_set_skew(
  mnn_cv_matrix_t self$1,
  double kx,
  double ky,
  double px,
  double py,
);

@ffi.Native<ffi.Void Function(mnn_cv_matrix_t, ffi.Float, ffi.Float)>()
external void mnn_cv_matrix_set_translate(
  mnn_cv_matrix_t self$1,
  double dx,
  double dy,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Abs(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Acos(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Acosh(
  VARP_t x,
);

/// Math Op
/// BinaryOPs
@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Add(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Int)>()
external VARP_t mnn_expr_ArgMax(
  VARP_t input,
  int axis,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Int)>()
external VARP_t mnn_expr_ArgMin(
  VARP_t input,
  int axis,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Asin(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Asinh(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Atan(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Atan2(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Atanh(
  VARP_t x,
);

@ffi.Native<
  VARP_t Function(
    VARP_t,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
    ffi.Int,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
  )
>()
external VARP_t mnn_expr_AvePool(
  VARP_t x,
  ffi.Pointer<ffi.Int> kernel,
  int kernelLength,
  ffi.Pointer<ffi.Int> stride,
  int strideLength,
  int pad,
  ffi.Pointer<ffi.Int> pads,
  int padsLength,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Bool, ffi.Bool)>()
external VARP_t mnn_expr_BatchMatMul(
  VARP_t x,
  VARP_t y,
  bool adj_x,
  bool adj_y,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t)>()
external VARP_t mnn_expr_BatchToSpaceND(
  VARP_t input,
  VARP_t block_shape,
  VARP_t crops,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_BiasAdd(
  VARP_t value,
  VARP_t bias,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_BitwiseAnd(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_BitwiseOr(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_BitwiseXor(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_BroadcastTo(
  VARP_t a,
  VARP_t shape,
);

/// OtherOPs
/// template<typename T>
/// VARP _Cast(VARP x) {
/// return _Cast(x, halide_type_of<T>());
/// }
@ffi.Native<VARP_t Function(VARP_t, halide_type_c_t)>()
external VARP_t mnn_expr_Cast(
  VARP_t x,
  halide_type_c_t dtype,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Ceil(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Int)>()
external VARP_t mnn_expr_ChangeInputFormat(
  VARP_t input,
  int format,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Int)>()
external VARP_t mnn_expr_ChannelShuffle(
  VARP_t x,
  int group,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Bool)>()
external VARP_t mnn_expr_Clone(
  VARP_t source,
  bool deepCopy,
);

@ffi.Native<
  VARP_t Function(
    VARP_t,
    VARP_t,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
  )
>()
external VARP_t mnn_expr_Col2Im(
  VARP_t x,
  VARP_t outputShape,
  ffi.Pointer<ffi.Int> kernelSize,
  int kernelSizeLength,
  ffi.Pointer<ffi.Int> dilate,
  int dilateLength,
  ffi.Pointer<ffi.Int> pads,
  int padsLength,
  ffi.Pointer<ffi.Int> stride,
  int strideLength,
);

@ffi.Native<VARP_t Function(VecVARP_t, ffi.Int)>()
external VARP_t mnn_expr_Concat(
  VecVARP_t values,
  int axis,
);

@ffi.Native<
  VARP_t Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Int>, ffi.Size, ffi.Int, halide_type_c_t)
>()
external VARP_t mnn_expr_Const(
  ffi.Pointer<ffi.Void> value,
  ffi.Pointer<ffi.Int> shape,
  int shapeLength,
  int format,
  halide_type_c_t type,
);

/// MNN_PUBLIC VARP _InnerProduct(std::vector<float>&& weight, std::vector<float>&& bias, VARP x,
/// INTS outputShape);
@ffi.Native<
  VARP_t Function(
    VARP_t,
    VARP_t,
    VARP_t,
    ffi.Int,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
    ffi.Int,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
  )
>()
external VARP_t mnn_expr_Conv(
  VARP_t weight,
  VARP_t bias,
  VARP_t x,
  int pad,
  ffi.Pointer<ffi.Int> stride,
  int strideLength,
  ffi.Pointer<ffi.Int> dilate,
  int dilateLength,
  int group,
  ffi.Pointer<ffi.Int> pads,
  int padsLength,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Int)>()
external VARP_t mnn_expr_Convert(
  VARP_t input,
  int format,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Cos(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Cosh(
  VARP_t x,
);

/// Int8 Inference
/// MNN_PUBLIC VARP _Conv(std::vector<int8_t>&& weight, std::vector<int>&& bias, std::vector<float>&&
/// scale, VARP x, INTS channel, INTS kernelSize,
/// PaddingMode pad, INTS stride, INTS dilate, int group, INTS pads, bool relu,
/// int nbits = 8);
/// MNN_PUBLIC VARP _Conv(std::vector<int8_t>&& weight, std::vector<int>&& bias, std::vector<float>&&
/// scale,
/// VARP x, INTS channel, INTS kernelSize,
/// PaddingMode pad, INTS stride, INTS dilate, int group, INTS pads, bool relu,
/// int8_t inputZeroPoint, int8_t outputZeroPoint,
/// int8_t minValue, int8_t maxValue, bool accumulateToInt16);
/// MNN_PUBLIC VARP _Conv(std::vector<int8_t>&& weight, std::vector<float>&& bias,
/// std::vector<float>&& weightScale,
/// VARP x, INTS channel, INTS kernelSize,
/// PaddingMode pad, INTS stride, INTS dilate, int group, INTS pads, bool relu,
/// float scaleIn, float scaleOut,
/// int8_t inputZeroPoint, int8_t outputZeroPoint,
/// int8_t minValue, int8_t maxValue, float weightClampValue, bool
/// accumulateToInt16);
@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t)>()
external VARP_t mnn_expr_CosineSimilarity(
  VARP_t input0,
  VARP_t input1,
  VARP_t inputDim,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Int, ffi.Pointer<ffi.Int>, ffi.Size)>()
external VARP_t mnn_expr_Crop(
  VARP_t images,
  VARP_t size,
  int axis,
  ffi.Pointer<ffi.Int> offset,
  int offsetLength,
);

/// enum InterpolationMethod {BILINEAR, NEAREST};
@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t, VARP_t, ffi.Int, ffi.Float)>()
external VARP_t mnn_expr_CropAndResize(
  VARP_t image,
  VARP_t boxes,
  VARP_t box_ind,
  VARP_t crop_size,
  int method,
  double extrapolation_value,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Int)>()
external VARP_t mnn_expr_CumProd(
  VARP_t x,
  int axis,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Int, ffi.Bool, ffi.Bool)>()
external VARP_t mnn_expr_CumSum(
  VARP_t x,
  int axis,
  bool exclusive,
  bool reverse,
);

@ffi.Native<
  VARP_t Function(
    VARP_t,
    VARP_t,
    VARP_t,
    ffi.Int,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
    ffi.Int,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
  )
>()
external VARP_t mnn_expr_Deconv(
  VARP_t weight,
  VARP_t bias,
  VARP_t x,
  int pad,
  ffi.Pointer<ffi.Int> stride,
  int strideLength,
  ffi.Pointer<ffi.Int> dilate,
  int dilateLength,
  int group,
  ffi.Pointer<ffi.Int> pads,
  int padsLength,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Int)>()
external VARP_t mnn_expr_DepthToSpace(
  VARP_t input,
  int block_size,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Divide(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Float)>()
external VARP_t mnn_expr_Elu(
  VARP_t features,
  double alpha,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Equal(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Erf(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Erfc(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Erfinv(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Exp(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Int)>()
external VARP_t mnn_expr_ExpandDims(
  VARP_t input,
  int axis,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_ExpandDims_1(
  VARP_t input,
  VARP_t axis,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Expm1(
  VARP_t x,
);

/// MNN::Express::Expr
@ffi.Native<EXPRP_t Function()>()
external EXPRP_t mnn_expr_Expr_create_empty();

@ffi.Native<ffi.Void Function(EXPRP_t)>()
external void mnn_expr_Expr_free(
  EXPRP_t self$1,
);

@ffi.Native<VecVARP_t Function(EXPRP_t)>()
external VecVARP_t mnn_expr_Expr_getInputs(
  EXPRP_t self$1,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(EXPRP_t)>()
external ffi.Pointer<ffi.Char> mnn_expr_Expr_getName(
  EXPRP_t self$1,
);

@ffi.Native<Op_t Function(EXPRP_t)>()
external Op_t mnn_expr_Expr_getOp(
  EXPRP_t self$1,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(EXPRP_t, ffi.Int)>()
external ffi.Pointer<ffi.Char> mnn_expr_Expr_getOutputName(
  EXPRP_t self$1,
  int index,
);

@ffi.Native<ffi.Int Function(EXPRP_t)>()
external int mnn_expr_Expr_getOutputSize(
  EXPRP_t self$1,
);

@ffi.Native<VecWeakEXPRP_t Function(EXPRP_t)>()
external VecWeakEXPRP_t mnn_expr_Expr_getOutputs(
  EXPRP_t self$1,
);

@ffi.Native<ffi.Int Function(EXPRP_t)>()
external int mnn_expr_Expr_inputType(
  EXPRP_t self$1,
);

/// MNN_C_API void mnn_expr_Expr_visitOutputs();
@ffi.Native<ffi.Pointer<mnn_expr_Variable_Info> Function(EXPRP_t, ffi.Int)>()
external ffi.Pointer<mnn_expr_Variable_Info> mnn_expr_Expr_outputInfo(
  EXPRP_t self$1,
  int index,
);

@ffi.Native<ffi.Bool Function(EXPRP_t)>()
external bool mnn_expr_Expr_requireInfo(
  EXPRP_t self$1,
);

@ffi.Native<ffi.Void Function(EXPRP_t, ffi.Pointer<ffi.Char>)>()
external void mnn_expr_Expr_setName(
  EXPRP_t self$1,
  ffi.Pointer<ffi.Char> name,
);

@ffi.Native<EXPRP_t Function(mnn_tensor_t, ffi.Bool)>()
external EXPRP_t mnn_expr_Expr_static_create(
  mnn_tensor_t tensor,
  bool own,
);

@ffi.Native<EXPRP_t Function(ffi.Pointer<mnn_expr_Variable_Info>, ffi.Pointer<ffi.Void>, ffi.Int, ffi.Int)>()
external EXPRP_t mnn_expr_Expr_static_create_1(
  ffi.Pointer<mnn_expr_Variable_Info> info,
  ffi.Pointer<ffi.Void> ptr,
  int type,
  int memoryType,
);

@ffi.Native<EXPRP_t Function(OpT_t, VecVARP_t, ffi.Int)>()
external EXPRP_t mnn_expr_Expr_static_create_2(
  OpT_t op,
  VecVARP_t inputs,
  int outputSize,
);

@ffi.Native<ffi.Void Function(EXPRP_t, EXPRP_t)>()
external void mnn_expr_Expr_static_replace(
  EXPRP_t oldExpr,
  EXPRP_t newExpr,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Fill(
  VARP_t dims,
  VARP_t value,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Char, ffi.Char)>()
external VARP_t mnn_expr_FloatToInt8(
  VARP_t x,
  VARP_t scale,
  int minValue,
  int maxValue,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Int8, ffi.Int8, ffi.Int8)>()
external VARP_t mnn_expr_FloatToInt8_1(
  VARP_t x,
  VARP_t scale,
  int minValue,
  int maxValue,
  int zeroPoint,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Floor(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_FloorDiv(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_FloorMod(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Gather(
  VARP_t params,
  VARP_t indices,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_GatherElements(
  VARP_t params,
  VARP_t indices,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t)>()
external VARP_t mnn_expr_GatherElements_1(
  VARP_t params,
  VARP_t indices,
  VARP_t axis,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_GatherND(
  VARP_t params,
  VARP_t indices,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t)>()
external VARP_t mnn_expr_GatherV2(
  VARP_t params,
  VARP_t indices,
  VARP_t axis,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Gelu(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Greater(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_GreaterEqual(
  VARP_t x,
  VARP_t y,
);

/// enum GridSamplePaddingMode {GRID_SAMPLE_PADDING_ZEROS, GRID_SAMPLE_PADDING_BORDER,
/// GRID_SAMPLE_PADDING_REFLECTION};
@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Int, ffi.Int, ffi.Bool)>()
external VARP_t mnn_expr_GridSample(
  VARP_t input,
  VARP_t grid,
  int mode,
  int paddingMode,
  bool alignCorners,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Hardswish(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Int, ffi.Int, ffi.Int, ffi.Int)>()
external VARP_t mnn_expr_Histogram(
  VARP_t x,
  int bin,
  int min,
  int max,
  int channel,
);

@ffi.Native<
  VARP_t Function(
    VARP_t,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
  )
>()
external VARP_t mnn_expr_Im2Col(
  VARP_t x,
  ffi.Pointer<ffi.Int> kernelSize,
  int kernelSizeLength,
  ffi.Pointer<ffi.Int> dilate,
  int dilateLength,
  ffi.Pointer<ffi.Int> pads,
  int padsLength,
  ffi.Pointer<ffi.Int> stride,
  int strideLength,
);

/// Neural Network Ops
@ffi.Native<VARP_t Function(ffi.Pointer<ffi.Int>, ffi.Size, ffi.Int, halide_type_c_t)>()
external VARP_t mnn_expr_Input(
  ffi.Pointer<ffi.Int> shape,
  int shapeLength,
  int data_format,
  halide_type_c_t dtype,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Int8ToFloat(
  VARP_t x,
  VARP_t scale,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Int8)>()
external VARP_t mnn_expr_Int8ToFloat_1(
  VARP_t x,
  VARP_t scale,
  int zeroPoint,
);

/// MNN_PUBLIC VARP _DetectionOutput(VARP location, VARP confidence, VARP priorbox,
/// unsigned int num_classes, bool share_location, int background_label_id,
/// float nms_threshhold, int nms_topk, int code_type,
/// bool variance_encoded_in_target,
/// int keep_top_k, float confidence_threshold, float visualize_threshold);
/// MNN_PUBLIC  std::vector<VARP> _DetectionPostProcess(VARP encode_boxes, VARP class_predictions,
/// VARP anchors,
/// int num_classes, int max_detections,
/// int max_class_per_detection, int detections_per_class,
/// float nms_threshold, float iou_threshold,
/// bool use_regular_nms, std::vector<float> centersize_encoding);
@ffi.Native<VARP_t Function(VecVARP_t, ffi.Float, ffi.Float, ffi.Int, ffi.Int, ffi.Int, ffi.Bool)>()
external VARP_t mnn_expr_Interp(
  VecVARP_t xs,
  double widthScale,
  double heightScale,
  int outputWidth,
  int outputHeight,
  int resizeType,
  bool alignCorners,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Less(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_LessEqual(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t)>()
external VARP_t mnn_expr_LinSpace(
  VARP_t start,
  VARP_t stop,
  VARP_t num,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Log(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Log1p(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_LogicalOr(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Bool, ffi.Bool)>()
external VARP_t mnn_expr_MatMul(
  VARP_t a,
  VARP_t b,
  bool tranposeA,
  bool tranposeB,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t)>()
external VARP_t mnn_expr_MatrixBandPart(
  VARP_t input,
  VARP_t num_lower,
  VARP_t num_upper,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Pointer<ffi.Float>, ffi.Size)>()
external VARP_t mnn_expr_Max(
  VARP_t a,
  VARP_t b,
  ffi.Pointer<ffi.Float> coeff,
  int coeffSize,
);

@ffi.Native<
  VARP_t Function(
    VARP_t,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
    ffi.Int,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
  )
>()
external VARP_t mnn_expr_MaxPool(
  VARP_t x,
  ffi.Pointer<ffi.Int> kernel,
  int kernelLength,
  ffi.Pointer<ffi.Int> stride,
  int strideLength,
  int pad,
  ffi.Pointer<ffi.Int> pads,
  int padsLength,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Maximum(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Minimum(
  VARP_t x,
  VARP_t y,
);

/// MNN_PUBLIC VARP _EltwiseProdInt8(VARP x, VARP y,
/// std::vector<int8_t> x_weight, std::vector<int32_t> x_bias, std::vector<float>
/// x_scale, std::vector<float> x_tensorScale, std::vector<int8_t> y_weight,
/// std::vector<int32_t> y_bias, std::vector<float> y_scale, std::vector<float>
/// y_tensorScale, std::vector<int8_t> output_weight, std::vector<int32_t>
/// output_bias, std::vector<float> output_scale, std::vector<float>
/// output_tensorScale);
/// MNN_PUBLIC VARP _EltwiseSumInt8(VARP x, VARP y,
/// std::vector<int8_t> x_weight, std::vector<int32_t> x_bias,
/// std::vector<float> x_scale, std::vector<float> x_tensorScale,
/// std::vector<int8_t> y_weight, std::vector<int32_t> y_bias, std::vector<float>
/// y_scale, std::vector<float> y_tensorScale, std::vector<int8_t> output_weight,
/// std::vector<int32_t> output_bias, std::vector<float> output_scale,
/// std::vector<float> output_tensorScale);
/// MNN_PUBLIC VARP _EltwiseSubInt8(VARP x, VARP y,
/// std::vector<int8_t> x_weight, std::vector<int32_t> x_bias,
/// std::vector<float> x_scale, std::vector<float> x_tensorScale,
/// std::vector<int8_t> y_weight, std::vector<int32_t> y_bias, std::vector<float>
/// y_scale, std::vector<float> y_tensorScale, std::vector<int8_t> output_weight,
/// std::vector<int32_t> output_bias, std::vector<float> output_scale,
/// std::vector<float> output_tensorScale);
/// MNN_PUBLIC VARP _EltwiseMaxInt8(VARP x, VARP y,
/// std::vector<int8_t> x_weight, std::vector<int32_t> x_bias,
/// std::vector<float> x_scale, std::vector<float> x_tensorScale,
/// std::vector<int8_t> y_weight, std::vector<int32_t> y_bias, std::vector<float>
/// y_scale, std::vector<float> y_tensorScale, std::vector<int8_t> output_weight,
/// std::vector<int32_t> output_bias, std::vector<float> output_scale,
/// std::vector<float> output_tensorScale);
@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Mod(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VecVARP_t Function(VARP_t, ffi.Pointer<ffi.Int>, ffi.Size, VARP_t, ffi.Bool)>()
external VecVARP_t mnn_expr_Moments(
  VARP_t x,
  ffi.Pointer<ffi.Int> axis,
  int axisLength,
  VARP_t shift,
  bool keepDims,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Multiply(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Negative(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Int, ffi.Float, ffi.Float)>()
external VARP_t mnn_expr_Nms(
  VARP_t boxes,
  VARP_t scores,
  int maxDetections,
  double iouThreshold,
  double scoreThreshold,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Int32, ffi.Int32, ffi.Float, ffi.Pointer<ffi.Float>, ffi.Size)>()
external VARP_t mnn_expr_Normalize(
  VARP_t x,
  int acrossSpatial,
  int channelShared,
  double eps,
  ffi.Pointer<ffi.Float> scale,
  int scaleLength,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_NotEqual(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t, VARP_t, ffi.Int)>()
external VARP_t mnn_expr_OneHot(
  VARP_t indices,
  VARP_t depth,
  VARP_t onValue,
  VARP_t offValue,
  int axis,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Pointer<ffi.Float>, ffi.Size)>()
external VARP_t mnn_expr_PRelu(
  VARP_t x,
  ffi.Pointer<ffi.Float> slopes,
  int slopeLength,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Int)>()
external VARP_t mnn_expr_Pad(
  VARP_t x,
  VARP_t paddings,
  int mode,
);

/// MNN_PUBLIC VARP _PriorBox(VARP feature, VARP image,
/// std::vector<float> min_size, std::vector<float> max_size,
/// std::vector<float>aspect_ratio, bool flip, bool clip,
/// std::vector<float>variance, unsigned int img_h, unsigned int img_w,
/// float step_h, float step_w, float offset = 0.5);
@ffi.Native<VARP_t Function(VARP_t, ffi.Pointer<ffi.Int>, ffi.Size)>()
external VARP_t mnn_expr_Permute(
  VARP_t input,
  ffi.Pointer<ffi.Int> dims,
  int dimsLength,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Pow(
  VARP_t x,
  VARP_t y,
);

/// EltwiseOPs
@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Pointer<ffi.Float>, ffi.Size)>()
external VARP_t mnn_expr_Prod(
  VARP_t a,
  VARP_t b,
  ffi.Pointer<ffi.Float> coeff,
  int coeffSize,
);

@ffi.Native<VARP_t Function(VARP_t, halide_type_c_t, ffi.Float, ffi.Float, ffi.Int, ffi.Int)>()
external VARP_t mnn_expr_RandomUniform(
  VARP_t shape,
  halide_type_c_t dtype,
  double low,
  double high,
  int seed0,
  int seed1,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t)>()
external VARP_t mnn_expr_Range(
  VARP_t start,
  VARP_t limit,
  VARP_t delta,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Rank(
  VARP_t input,
);

@ffi.Native<VARP_t Function(VecVARP_t, ffi.Pointer<ffi.Int>, ffi.Size, ffi.Pointer<ffi.Int>, ffi.Size)>()
external VARP_t mnn_expr_Raster(
  VecVARP_t vars,
  ffi.Pointer<ffi.Int> regions,
  int regionsLength,
  ffi.Pointer<ffi.Int> shape,
  int shapeLength,
);

@ffi.Native<
  VARP_t Function(
    VecVARP_t,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
    ffi.Pointer<ffi.Int>,
    ffi.Size,
    halide_type_t,
    ffi.Int,
  )
>()
external VARP_t mnn_expr_RasterRaw(
  VecVARP_t vars,
  ffi.Pointer<ffi.Int> region,
  int regionLength,
  ffi.Pointer<ffi.Int> shape,
  int shapeLength,
  halide_type_t dataType,
  int format,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Reciprocal(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t, VecI32, ffi.Bool)>()
external VARP_t mnn_expr_ReduceAll(
  VARP_t input_variable,
  VecI32 axis,
  bool keepDims,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Bool)>()
external VARP_t mnn_expr_ReduceAllMutable(
  VARP_t input_variable,
  VARP_t axis,
  bool keepDims,
);

@ffi.Native<VARP_t Function(VARP_t, VecI32, ffi.Bool)>()
external VARP_t mnn_expr_ReduceAny(
  VARP_t input_variable,
  VecI32 axis,
  bool keepDims,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Bool)>()
external VARP_t mnn_expr_ReduceAnyMutable(
  VARP_t input_variable,
  VARP_t axis,
  bool keepDims,
);

@ffi.Native<VARP_t Function(VARP_t, VecI32, ffi.Bool)>()
external VARP_t mnn_expr_ReduceMax(
  VARP_t input_variable,
  VecI32 axis,
  bool keepDims,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Bool)>()
external VARP_t mnn_expr_ReduceMaxMutable(
  VARP_t input_variable,
  VARP_t axis,
  bool keepDims,
);

@ffi.Native<VARP_t Function(VARP_t, VecI32, ffi.Bool)>()
external VARP_t mnn_expr_ReduceMean(
  VARP_t input_variable,
  VecI32 axis,
  bool keepDims,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Bool)>()
external VARP_t mnn_expr_ReduceMeanMutable(
  VARP_t input_variable,
  VARP_t axis,
  bool keepDims,
);

@ffi.Native<VARP_t Function(VARP_t, VecI32, ffi.Bool)>()
external VARP_t mnn_expr_ReduceMin(
  VARP_t input_variable,
  VecI32 axis,
  bool keepDims,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Bool)>()
external VARP_t mnn_expr_ReduceMinMutable(
  VARP_t input_variable,
  VARP_t axis,
  bool keepDims,
);

@ffi.Native<VARP_t Function(VARP_t, VecI32, ffi.Bool)>()
external VARP_t mnn_expr_ReduceProd(
  VARP_t input_variable,
  VecI32 axis,
  bool keepDims,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Bool)>()
external VARP_t mnn_expr_ReduceProdMutable(
  VARP_t input_variable,
  VARP_t axis,
  bool keepDims,
);

/// ReduceOPs
@ffi.Native<VARP_t Function(VARP_t, VecI32, ffi.Bool)>()
external VARP_t mnn_expr_ReduceSum(
  VARP_t input_variable,
  VecI32 axis,
  bool keepDims,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Bool)>()
external VARP_t mnn_expr_ReduceSumMutable(
  VARP_t input_variable,
  VARP_t axis,
  bool keepDims,
);

@ffi.Native<VARP_t Function(VARP_t, VecI32, ffi.Bool)>()
external VARP_t mnn_expr_ReduceVariance(
  VARP_t input_variable,
  VecI32 axis,
  bool keepDims,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Float)>()
external VARP_t mnn_expr_Relu(
  VARP_t x,
  double slope,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Float, ffi.Float)>()
external VARP_t mnn_expr_Relu6(
  VARP_t x,
  double minValue,
  double maxValue,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Pointer<ffi.Int>, ffi.Size, ffi.Int)>()
external VARP_t mnn_expr_Reshape(
  VARP_t x,
  ffi.Pointer<ffi.Int> shape,
  int shapeLength,
  int original_format,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Reshape_1(
  VARP_t x,
  VARP_t shape,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Float, ffi.Float)>()
external VARP_t mnn_expr_Resize(
  VARP_t images,
  double xScale,
  double yScale,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Reverse(
  VARP_t x,
  VARP_t axis,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Int, ffi.Int)>()
external VARP_t mnn_expr_ReverseSequence(
  VARP_t x,
  VARP_t y,
  int batchDim,
  int seqDim,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Round(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Rsqrt(
  VARP_t x,
);

@ffi.Native<VARP_t Function(ffi.Pointer<ffi.Void>, halide_type_c_t)>()
external VARP_t mnn_expr_Scalar(
  ffi.Pointer<ffi.Void> ptr,
  halide_type_c_t type,
);

@ffi.Native<
  VARP_t Function(VARP_t, ffi.Int, ffi.Pointer<ffi.Float>, ffi.Size, ffi.Pointer<ffi.Float>, ffi.Size)
>()
external VARP_t mnn_expr_Scale(
  VARP_t x,
  int channels,
  ffi.Pointer<ffi.Float> scales,
  int scaleLength,
  ffi.Pointer<ffi.Float> bias,
  int biasLength,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t, ffi.Int)>()
external VARP_t mnn_expr_ScatterElements(
  VARP_t data,
  VARP_t indices,
  VARP_t updates,
  int reduction,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t, VARP_t, ffi.Int)>()
external VARP_t mnn_expr_ScatterElements_1(
  VARP_t data,
  VARP_t indices,
  VARP_t updates,
  VARP_t axis,
  int reduction,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t)>()
external VARP_t mnn_expr_ScatterNd(
  VARP_t indices,
  VARP_t updates,
  VARP_t shape,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t, VARP_t)>()
external VARP_t mnn_expr_ScatterNd_1(
  VARP_t indices,
  VARP_t updates,
  VARP_t shape,
  VARP_t input,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t, ffi.Int)>()
external VARP_t mnn_expr_ScatterNd_2(
  VARP_t indices,
  VARP_t updates,
  VARP_t shape,
  int reduction,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t, VARP_t, ffi.Int)>()
external VARP_t mnn_expr_ScatterNd_3(
  VARP_t indices,
  VARP_t updates,
  VARP_t shape,
  VARP_t input,
  int reduction,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t)>()
external VARP_t mnn_expr_Select(
  VARP_t select,
  VARP_t input0,
  VARP_t input1,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Float, ffi.Float)>()
external VARP_t mnn_expr_Selu(
  VARP_t features,
  double scale,
  double alpha,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_SetDiff1D(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Bool)>()
external VARP_t mnn_expr_Shape(
  VARP_t input,
  bool nchw,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Sigmoid(
  VARP_t x,
);

/// UnaryOPs
@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Sign(
  VARP_t a,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Silu(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Sin(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Sinh(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Size(
  VARP_t input,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t)>()
external VARP_t mnn_expr_Slice(
  VARP_t x,
  VARP_t starts,
  VARP_t sizes,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Int)>()
external VARP_t mnn_expr_Softmax(
  VARP_t logits,
  int axis,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Softplus(
  VARP_t features,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Softsign(
  VARP_t features,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Int, ffi.Bool, ffi.Bool)>()
external VARP_t mnn_expr_Sort(
  VARP_t x,
  int axis,
  bool arg,
  bool descend,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, VARP_t)>()
external VARP_t mnn_expr_SpaceToBatchND(
  VARP_t input,
  VARP_t block_shape,
  VARP_t paddings,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Int)>()
external VARP_t mnn_expr_SpaceToDepth(
  VARP_t input,
  int block_size,
);

@ffi.Native<VecVARP_t Function(VARP_t, ffi.Pointer<ffi.Int>, ffi.Size, ffi.Int)>()
external VecVARP_t mnn_expr_Split(
  VARP_t value,
  ffi.Pointer<ffi.Int> size_splits,
  int size_splitsLength,
  int axis,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Sqrt(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Square(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_SquaredDifference(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Pointer<ffi.Int>, ffi.Size)>()
external VARP_t mnn_expr_Squeeze(
  VARP_t input,
  ffi.Pointer<ffi.Int> axis,
  int axisLength,
);

@ffi.Native<VARP_t Function(VecVARP_t, ffi.Int)>()
external VARP_t mnn_expr_Stack(
  VecVARP_t values,
  int axis,
);

@ffi.Native<
  VARP_t Function(VARP_t, VARP_t, VARP_t, VARP_t, ffi.Int32, ffi.Int32, ffi.Int32, ffi.Int32, ffi.Int32)
>()
external VARP_t mnn_expr_StridedSlice(
  VARP_t input,
  VARP_t begin,
  VARP_t end,
  VARP_t strided,
  int beginMask,
  int endMask,
  int ellipsisMask,
  int newAxisMask,
  int shrinkAxisMask,
);

@ffi.Native<
  VARP_t Function(
    VARP_t,
    VARP_t,
    VARP_t,
    VARP_t,
    VARP_t,
    ffi.Int32,
    ffi.Int32,
    ffi.Int32,
    ffi.Int32,
    ffi.Int32,
  )
>()
external VARP_t mnn_expr_StridedSliceWrite(
  VARP_t input,
  VARP_t begin,
  VARP_t end,
  VARP_t strided,
  VARP_t write,
  int beginMask,
  int endMask,
  int ellipsisMask,
  int newAxisMask,
  int shrinkAxisMask,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Pointer<ffi.Float>, ffi.Size)>()
external VARP_t mnn_expr_Sub(
  VARP_t a,
  VARP_t b,
  ffi.Pointer<ffi.Float> coeff,
  int coeffSize,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Subtract(
  VARP_t x,
  VARP_t y,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t, ffi.Pointer<ffi.Float>, ffi.Size)>()
external VARP_t mnn_expr_Sum(
  VARP_t a,
  VARP_t b,
  ffi.Pointer<ffi.Float> coeff,
  int coeffSize,
);

@ffi.Native<VecVARP_t Function(VARP_t)>()
external VecVARP_t mnn_expr_Svd(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Tan(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Tanh(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Float)>()
external VARP_t mnn_expr_Threshold(
  VARP_t features,
  double alpha,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Tile(
  VARP_t input,
  VARP_t multiples,
);

@ffi.Native<VecVARP_t Function(VARP_t, VARP_t)>()
external VecVARP_t mnn_expr_TopKV2(
  VARP_t input0,
  VARP_t input1,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Pointer<ffi.Int>, ffi.Size)>()
external VARP_t mnn_expr_Transpose(
  VARP_t x,
  ffi.Pointer<ffi.Int> perm,
  int permLength,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_Transpose_1(
  VARP_t x,
  VARP_t perm,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_UnravelIndex(
  VARP_t indices,
  VARP_t dims,
);

@ffi.Native<VARP_t Function(VARP_t, ffi.Pointer<ffi.Int>, ffi.Size)>()
external VARP_t mnn_expr_Unsqueeze(
  VARP_t input,
  ffi.Pointer<ffi.Int> axis,
  int axisLength,
);

@ffi.Native<VecVARP_t Function(VARP_t, ffi.Int)>()
external VecVARP_t mnn_expr_Unstack(
  VARP_t value,
  int axis,
);

@ffi.Native<VARMAP_t Function()>()
external VARMAP_t mnn_expr_VARMAP_create();

@ffi.Native<ffi.Void Function(ffi.Pointer<ffi.Void>)>()
external void mnn_expr_VARMAP_free(
  ffi.Pointer<ffi.Void> self$1,
);

@ffi.Native<VARP_t Function(VARMAP_t, ffi.Pointer<ffi.Char>)>()
external VARP_t mnn_expr_VARMAP_get(
  VARMAP_t self$1,
  ffi.Pointer<ffi.Char> key,
);

@ffi.Native<VARP_t Function(VARMAP_t, ffi.Pointer<ffi.Char>)>()
external VARP_t mnn_expr_VARMAP_get_ref(
  VARMAP_t self$1,
  ffi.Pointer<ffi.Char> key,
);

@ffi.Native<ffi.Pointer<ffi.Pointer<ffi.Char>> Function(VARMAP_t)>()
external ffi.Pointer<ffi.Pointer<ffi.Char>> mnn_expr_VARMAP_keys(
  VARMAP_t self$1,
);

@ffi.Native<ffi.Void Function(VARMAP_t, ffi.Pointer<ffi.Char>, VARP_t)>()
external void mnn_expr_VARMAP_set(
  VARMAP_t self$1,
  ffi.Pointer<ffi.Char> key,
  VARP_t value,
);

@ffi.Native<ffi.Size Function(VARMAP_t)>()
external int mnn_expr_VARMAP_size(
  VARMAP_t self$1,
);

@ffi.Native<ffi.Bool Function(VARP_t, ffi.Pointer<ffi.Void>, ffi.Int)>()
external bool mnn_expr_VARP_copyToDevicePtr(
  VARP_t self$1,
  ffi.Pointer<ffi.Void> devicePtr,
  int memoryType,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_VARP_create_VARP(
  VARP_t other,
);

/// MNN::Express::VARP
@ffi.Native<VARP_t Function()>()
external VARP_t mnn_expr_VARP_create_empty();

@ffi.Native<ffi.Bool Function(VARP_t, ffi.Int)>()
external bool mnn_expr_VARP_fix(
  VARP_t self$1,
  int type,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<ffi.Void>)>()
external void mnn_expr_VARP_free(
  ffi.Pointer<ffi.Void> self$1,
);

@ffi.Native<ffi.Pointer<Variable_expr_pair> Function(VARP_t)>()
external ffi.Pointer<Variable_expr_pair> mnn_expr_VARP_getExpr(
  VARP_t self$1,
);

@ffi.Native<ffi.Pointer<mnn_expr_Variable_Info> Function(VARP_t)>()
external ffi.Pointer<mnn_expr_Variable_Info> mnn_expr_VARP_getInfo(
  VARP_t self$1,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(VARP_t)>()
external ffi.Pointer<ffi.Char> mnn_expr_VARP_getName(
  VARP_t self$1,
);

@ffi.Native<mnn_tensor_t Function(VARP_t)>()
external mnn_tensor_t mnn_expr_VARP_getTensor(
  VARP_t self$1,
);

@ffi.Native<ffi.Bool Function(VARP_t, VARP_t)>()
external bool mnn_expr_VARP_input(
  VARP_t self$1,
  VARP_t src,
);

@ffi.Native<ffi.Size Function(VARP_t)>()
external int mnn_expr_VARP_linkNumber(
  VARP_t self$1,
);

@ffi.Native<VARP_t Function(VARP_t, VecI32)>()
external VARP_t mnn_expr_VARP_mean(
  VARP_t self$1,
  VecI32 dims,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_VARP_op_add(
  VARP_t self$1,
  VARP_t other,
);

@ffi.Native<ffi.Void Function(VARP_t, VARP_t)>()
external void mnn_expr_VARP_op_assign(
  VARP_t self$1,
  VARP_t other,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_VARP_op_div(
  VARP_t self$1,
  VARP_t other,
);

@ffi.Native<ffi.Bool Function(VARP_t, VARP_t)>()
external bool mnn_expr_VARP_op_eqeq(
  VARP_t self$1,
  VARP_t other,
);

@ffi.Native<ffi.Bool Function(VARP_t, VARP_t)>()
external bool mnn_expr_VARP_op_less(
  VARP_t self$1,
  VARP_t other,
);

@ffi.Native<ffi.Bool Function(VARP_t, VARP_t)>()
external bool mnn_expr_VARP_op_lessequal(
  VARP_t self$1,
  VARP_t other,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_VARP_op_mul(
  VARP_t self$1,
  VARP_t other,
);

@ffi.Native<VARP_t Function(VARP_t, VARP_t)>()
external VARP_t mnn_expr_VARP_op_sub(
  VARP_t self$1,
  VARP_t other,
);

@ffi.Native<ffi.Pointer<ffi.Void> Function(VARP_t)>()
external ffi.Pointer<ffi.Void> mnn_expr_VARP_readMap(
  VARP_t self$1,
);

@ffi.Native<ffi.Bool Function(VARP_t, VecI32)>()
external bool mnn_expr_VARP_resize(
  VARP_t self$1,
  VecI32 dims,
);

@ffi.Native<ffi.Bool Function(VARP_t, ffi.Pointer<ffi.Void>, ffi.Int)>()
external bool mnn_expr_VARP_setDevicePtr(
  VARP_t self$1,
  ffi.Pointer<ffi.Void> devicePtr,
  int memoryType,
);

@ffi.Native<ffi.Void Function(VARP_t, EXPRP_t, ffi.Int)>()
external void mnn_expr_VARP_setExpr(
  VARP_t self$1,
  EXPRP_t expr,
  int index,
);

/// MNN::Express::Variable
@ffi.Native<ffi.Void Function(VARP_t, ffi.Pointer<ffi.Char>)>()
external void mnn_expr_VARP_setName(
  VARP_t self$1,
  ffi.Pointer<ffi.Char> name,
);

@ffi.Native<ffi.Void Function(VARP_t, ffi.Int)>()
external void mnn_expr_VARP_setOrder(
  VARP_t self$1,
  int format,
);

@ffi.Native<ffi.Void Function(VecVARP_t, ffi.Bool)>()
external void mnn_expr_VARP_static_compute(
  VecVARP_t vars,
  bool forceCPU,
);

@ffi.Native<VARP_t Function(EXPRP_t, ffi.Int)>()
external VARP_t mnn_expr_VARP_static_create_EXPRP(
  EXPRP_t expr,
  int index,
);

@ffi.Native<VecVARP_t Function(ffi.Pointer<ffi.Char>)>()
external VecVARP_t mnn_expr_VARP_static_load(
  ffi.Pointer<ffi.Char> fileName,
);

@ffi.Native<VecVARP_t Function(ffi.Pointer<ffi.Uint8>, ffi.Size)>()
external VecVARP_t mnn_expr_VARP_static_loadBuffer(
  ffi.Pointer<ffi.Uint8> buffer,
  int length,
);

@ffi.Native<VARMAP_t Function(ffi.Pointer<ffi.Char>)>()
external VARMAP_t mnn_expr_VARP_static_loadMap(
  ffi.Pointer<ffi.Char> fileName,
);

@ffi.Native<VARMAP_t Function(ffi.Pointer<ffi.Uint8>, ffi.Size)>()
external VARMAP_t mnn_expr_VARP_static_loadMapBuffer(
  ffi.Pointer<ffi.Uint8> buffer,
  int length,
);

@ffi.Native<ffi.Void Function(VecVARP_t, ffi.Bool)>()
external void mnn_expr_VARP_static_prepareCompute(
  VecVARP_t vars,
  bool forceCPU,
);

@ffi.Native<ffi.Void Function(VARP_t, VARP_t)>()
external void mnn_expr_VARP_static_replace(
  VARP_t dst,
  VARP_t src,
);

/// MNN_C_API void mnn_expr_VARP_static_getExecuteOrder(VecVARP_t output);
@ffi.Native<ffi.Void Function(VecVARP_t, ffi.Pointer<ffi.Char>)>()
external void mnn_expr_VARP_static_save(
  VecVARP_t vars,
  ffi.Pointer<ffi.Char> fileName,
);

@ffi.Native<VecI8 Function(VecVARP_t)>()
external VecI8 mnn_expr_VARP_static_saveBytes(
  VecVARP_t vars,
);

@ffi.Native<ffi.Void Function(VecVARP_t, Net_t)>()
external void mnn_expr_VARP_static_saveNet(
  VecVARP_t vars,
  Net_t dest,
);

@ffi.Native<VARP_t Function(VARP_t, VecI32)>()
external VARP_t mnn_expr_VARP_sum(
  VARP_t self$1,
  VecI32 dims,
);

@ffi.Native<VecWeakEXPRP_t Function(VARP_t)>()
external VecWeakEXPRP_t mnn_expr_VARP_toExprs(
  VARP_t self$1,
);

@ffi.Native<ffi.Pointer<ffi.Void> Function(VARP_t)>()
external ffi.Pointer<ffi.Void> mnn_expr_VARP_writeMap(
  VARP_t self$1,
);

@ffi.Native<ffi.Void Function(VARP_t, ffi.Float, ffi.Float)>()
external void mnn_expr_VARP_writeScaleMap(
  VARP_t self$1,
  double scaleValue,
  double zeroPoint,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<ffi.Void>)>()
external void mnn_expr_Variable_Info_free(
  ffi.Pointer<ffi.Void> self$1,
);

@ffi.Native<VARP_t Function(VecVARP_t, ffi.Int)>()
external VARP_t mnn_expr_VecVARP_at(
  VecVARP_t self$1,
  int i,
);

@ffi.Native<VARP_t Function(VecVARP_t, ffi.Int)>()
external VARP_t mnn_expr_VecVARP_at_ref(
  VecVARP_t self$1,
  int i,
);

@ffi.Native<VecVARP_t Function(ffi.Size, VARP_t)>()
external VecVARP_t mnn_expr_VecVARP_create(
  int length,
  VARP_t value,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<ffi.Void>)>()
external void mnn_expr_VecVARP_free(
  ffi.Pointer<ffi.Void> self$1,
);

@ffi.Native<ffi.Void Function(VecVARP_t, VARP_t)>()
external void mnn_expr_VecVARP_push_back(
  VecVARP_t self$1,
  VARP_t value,
);

@ffi.Native<ffi.Void Function(VecVARP_t, ffi.Int, VARP_t)>()
external void mnn_expr_VecVARP_set(
  VecVARP_t self$1,
  int i,
  VARP_t value,
);

@ffi.Native<ffi.Size Function(VecVARP_t)>()
external int mnn_expr_VecVARP_size(
  VecVARP_t self$1,
);

@ffi.Native<EXPRP_t Function(VecWeakEXPRP_t, ffi.Int)>()
external EXPRP_t mnn_expr_VecWeakEXPRP_at(
  VecWeakEXPRP_t self$1,
  int i,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<ffi.Void>)>()
external void mnn_expr_VecWeakEXPRP_free(
  ffi.Pointer<ffi.Void> self$1,
);

@ffi.Native<ffi.Void Function(VecWeakEXPRP_t, EXPRP_t)>()
external void mnn_expr_VecWeakEXPRP_push_back(
  VecWeakEXPRP_t self$1,
  EXPRP_t value,
);

@ffi.Native<ffi.Void Function(VecWeakEXPRP_t, ffi.Int, EXPRP_t)>()
external void mnn_expr_VecWeakEXPRP_set(
  VecWeakEXPRP_t self$1,
  int i,
  EXPRP_t value,
);

@ffi.Native<ffi.Size Function(VecWeakEXPRP_t)>()
external int mnn_expr_VecWeakEXPRP_size(
  VecWeakEXPRP_t self$1,
);

/// MNN_PUBLIC VARP _ImageProcess(VARP input, CV::ImageProcess::Config config, CV::Matrix matrix, int
/// oh, int ow, int oc, int dtype, uint8_t padVal = 0); mnn_expr_VARP_t
/// mnn_expr_ImageProcess(mnn_expr_VARP_t input, CV::ImageProcess::Config config, CV::Matrix matrix,
/// int oh, int ow, int oc, int dtype, uint8_t padVal);
@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_Where(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_ZeroGrad(
  VARP_t x,
);

@ffi.Native<VARP_t Function(VARP_t)>()
external VARP_t mnn_expr_ZerosLike(
  VARP_t input,
);

/// @brief Get MNN version
/// @return Version string
@ffi.Native<ffi.Pointer<ffi.Char> Function()>()
external ffi.Pointer<ffi.Char> mnn_get_version();

/// @brief Get biz code from interpreter
/// @param self Interpreter instance
/// @return Biz code string or NULL if failed
@ffi.Native<ffi.Pointer<ffi.Char> Function(mnn_interpreter_t)>(isLeaf: true)
external ffi.Pointer<ffi.Char> mnn_interpreter_biz_code(
  mnn_interpreter_t self$1,
);

/// @brief Create interpreter from buffer
/// @param buffer Model data buffer
/// @param size Buffer size
/// @param callback Callback function to be called after creation
/// @return Interpreter instance or NULL if failed
@ffi.Native<mnn_interpreter_t Function(ffi.Pointer<ffi.Void>, ffi.Size, mnn_callback_0)>()
external mnn_interpreter_t mnn_interpreter_create_from_buffer(
  ffi.Pointer<ffi.Void> buffer,
  int size,
  mnn_callback_0 callback,
);

/// @brief Create interpreter from file
/// @param file_path Path to model file
/// @param callback Callback function to be called after creation
/// @return Interpreter instance or NULL if failed
@ffi.Native<mnn_interpreter_t Function(ffi.Pointer<ffi.Char>, mnn_callback_0)>()
external mnn_interpreter_t mnn_interpreter_create_from_file(
  ffi.Pointer<ffi.Char> file_path,
  mnn_callback_0 callback,
);

/// @brief Create runtime info
/// @param configs Schedule config array
/// @param count Config count
/// @return Runtime info instance
@ffi.Native<mnn_runtime_info_t Function(ffi.Pointer<mnn_schedule_config_t>, ffi.Size)>()
external mnn_runtime_info_t mnn_interpreter_create_runtime(
  ffi.Pointer<mnn_schedule_config_t> configs,
  int count,
);

/// @brief Create session with config
/// @param self Interpreter instance
/// @param config Schedule config
/// @param callback Callback function to be called after creation
/// @return Session instance or NULL if failed
@ffi.Native<mnn_session_t Function(mnn_interpreter_t, ffi.Pointer<mnn_schedule_config_t>, mnn_callback_0)>()
external mnn_session_t mnn_interpreter_create_session(
  mnn_interpreter_t self$1,
  ffi.Pointer<mnn_schedule_config_t> config,
  mnn_callback_0 callback,
);

/// @brief Create session with runtime info
/// @param self Interpreter instance
/// @param config Schedule config
/// @param runtime Runtime info
/// @param callback Callback function to be called after creation
/// @return Session instance or NULL if failed
@ffi.Native<
  mnn_session_t Function(
    mnn_interpreter_t,
    ffi.Pointer<mnn_schedule_config_t>,
    mnn_runtime_info_t,
    mnn_callback_0,
  )
>()
external mnn_session_t mnn_interpreter_create_session_with_runtime(
  mnn_interpreter_t self$1,
  ffi.Pointer<mnn_schedule_config_t> config,
  mnn_runtime_info_t runtime,
  mnn_callback_0 callback,
);

/// @brief Destroy interpreter instance
/// @param self Interpreter to destroy
@ffi.Native<ffi.Void Function(mnn_interpreter_t)>()
external void mnn_interpreter_destroy(
  mnn_interpreter_t self$1,
);

/// @brief Get backend type
/// @param self Interpreter instance
/// @param session Session
/// @return Backend type
@ffi.Native<mnn_backend_t Function(mnn_interpreter_t, mnn_session_t, mnn_tensor_t)>()
external mnn_backend_t mnn_interpreter_get_backend(
  mnn_interpreter_t self$1,
  mnn_session_t session,
  mnn_tensor_t tensor,
);

/// @brief Get model buffer
/// @param self Interpreter instance
/// @param buffer Output parameter to receive pointer to model data
/// @return Size of model data in bytes, or 0 if failed
@ffi.Native<ffi.Size Function(mnn_interpreter_t, ffi.Pointer<ffi.Pointer<ffi.Void>>)>()
external int mnn_interpreter_get_model_buffer(
  mnn_interpreter_t self$1,
  ffi.Pointer<ffi.Pointer<ffi.Void>> buffer,
);

/// @brief Get model version
/// @param self Interpreter instance
/// @return Version string or NULL if failed
@ffi.Native<ffi.Pointer<ffi.Char> Function(mnn_interpreter_t)>(isLeaf: true)
external ffi.Pointer<ffi.Char> mnn_interpreter_get_model_version(
  mnn_interpreter_t self$1,
);

/// @brief Get session info
/// @param self Interpreter instance
/// @param session Session
/// @param info Output parameter for session info
/// @return Error code
@ffi.Native<ffi.UnsignedInt Function(mnn_interpreter_t, mnn_session_t, ffi.Int, ffi.Pointer<ffi.Void>)>(
  symbol: 'mnn_interpreter_get_session_info',
)
external int _mnn_interpreter_get_session_info(
  mnn_interpreter_t self$1,
  mnn_session_t session,
  int session_info_code,
  ffi.Pointer<ffi.Void> info,
);

ErrorCode mnn_interpreter_get_session_info(
  mnn_interpreter_t self$1,
  mnn_session_t session,
  int session_info_code,
  ffi.Pointer<ffi.Void> info,
) => ErrorCode.fromValue(
  _mnn_interpreter_get_session_info(
    self$1,
    session,
    session_info_code,
    info,
  ),
);

/// @brief Get input tensor by name
/// @param self Interpreter instance
/// @param session Session
/// @param name Tensor name (NULL for first input)
/// @return Tensor instance or NULL if failed
@ffi.Native<mnn_tensor_t Function(mnn_interpreter_t, mnn_session_t, ffi.Pointer<ffi.Char>)>()
external mnn_tensor_t mnn_interpreter_get_session_input(
  mnn_interpreter_t self$1,
  mnn_session_t session,
  ffi.Pointer<ffi.Char> name,
);

/// @brief Get all input tensors from session
/// @param self Interpreter instance
/// @param session Session
/// @param tensors Output parameter for tensor array
/// @param count Output parameter for tensor count
/// @return Error code
@ffi.Native<
  ffi.UnsignedInt Function(
    mnn_interpreter_t,
    mnn_session_t,
    ffi.Pointer<ffi.Pointer<mnn_tensor_t>>,
    ffi.Pointer<ffi.Pointer<ffi.Pointer<ffi.Char>>>,
    ffi.Pointer<ffi.Size>,
  )
>(symbol: 'mnn_interpreter_get_session_input_all')
external int _mnn_interpreter_get_session_input_all(
  mnn_interpreter_t self$1,
  mnn_session_t session,
  ffi.Pointer<ffi.Pointer<mnn_tensor_t>> tensors,
  ffi.Pointer<ffi.Pointer<ffi.Pointer<ffi.Char>>> names,
  ffi.Pointer<ffi.Size> count,
);

ErrorCode mnn_interpreter_get_session_input_all(
  mnn_interpreter_t self$1,
  mnn_session_t session,
  ffi.Pointer<ffi.Pointer<mnn_tensor_t>> tensors,
  ffi.Pointer<ffi.Pointer<ffi.Pointer<ffi.Char>>> names,
  ffi.Pointer<ffi.Size> count,
) => ErrorCode.fromValue(
  _mnn_interpreter_get_session_input_all(
    self$1,
    session,
    tensors,
    names,
    count,
  ),
);

/// @brief Get output tensor by name
/// @param self Interpreter instance
/// @param session Session
/// @param name Tensor name (NULL for first output)
/// @return Tensor instance or NULL if failed
@ffi.Native<mnn_tensor_t Function(mnn_interpreter_t, mnn_session_t, ffi.Pointer<ffi.Char>)>()
external mnn_tensor_t mnn_interpreter_get_session_output(
  mnn_interpreter_t self$1,
  mnn_session_t session,
  ffi.Pointer<ffi.Char> name,
);

/// @brief Get all output tensors from session
/// @param self Interpreter instance
/// @param session Session
/// @param tensors Output parameter for tensor array
/// @param count Output parameter for tensor count
/// @return Error code
@ffi.Native<
  ffi.UnsignedInt Function(
    mnn_interpreter_t,
    mnn_session_t,
    ffi.Pointer<ffi.Pointer<mnn_tensor_t>>,
    ffi.Pointer<ffi.Pointer<ffi.Pointer<ffi.Char>>>,
    ffi.Pointer<ffi.Size>,
  )
>(symbol: 'mnn_interpreter_get_session_output_all')
external int _mnn_interpreter_get_session_output_all(
  mnn_interpreter_t self$1,
  mnn_session_t session,
  ffi.Pointer<ffi.Pointer<mnn_tensor_t>> tensors,
  ffi.Pointer<ffi.Pointer<ffi.Pointer<ffi.Char>>> names,
  ffi.Pointer<ffi.Size> count,
);

ErrorCode mnn_interpreter_get_session_output_all(
  mnn_interpreter_t self$1,
  mnn_session_t session,
  ffi.Pointer<ffi.Pointer<mnn_tensor_t>> tensors,
  ffi.Pointer<ffi.Pointer<ffi.Pointer<ffi.Char>>> names,
  ffi.Pointer<ffi.Size> count,
) => ErrorCode.fromValue(
  _mnn_interpreter_get_session_output_all(
    self$1,
    session,
    tensors,
    names,
    count,
  ),
);

/// @brief Release model
/// @param self Interpreter instance
@ffi.Native<ffi.Void Function(mnn_interpreter_t)>()
external void mnn_interpreter_release_model(
  mnn_interpreter_t self$1,
);

/// @brief Release session
/// @param self Interpreter instance
/// @param session Session to release
/// @param callback Callback function to be called after release
/// @return Error code
@ffi.Native<ffi.UnsignedInt Function(mnn_interpreter_t, mnn_session_t, mnn_callback_0)>(
  symbol: 'mnn_interpreter_release_session',
)
external int _mnn_interpreter_release_session(
  mnn_interpreter_t self$1,
  mnn_session_t session,
  mnn_callback_0 callback,
);

ErrorCode mnn_interpreter_release_session(
  mnn_interpreter_t self$1,
  mnn_session_t session,
  mnn_callback_0 callback,
) => ErrorCode.fromValue(
  _mnn_interpreter_release_session(
    self$1,
    session,
    callback,
  ),
);

/// @brief Resize session
/// @param self Interpreter instance
/// @param session Session to resize
/// @param callback Callback function to be called after resize
/// @return Error code
@ffi.Native<ffi.UnsignedInt Function(mnn_interpreter_t, mnn_session_t, mnn_callback_0)>(
  symbol: 'mnn_interpreter_resize_session',
)
external int _mnn_interpreter_resize_session(
  mnn_interpreter_t self$1,
  mnn_session_t session,
  mnn_callback_0 callback,
);

ErrorCode mnn_interpreter_resize_session(
  mnn_interpreter_t self$1,
  mnn_session_t session,
  mnn_callback_0 callback,
) => ErrorCode.fromValue(
  _mnn_interpreter_resize_session(
    self$1,
    session,
    callback,
  ),
);

/// @brief Resize tensor
/// @param tensor Tensor to resize
/// @param dims New dimensions array
/// @param dim_count Dimension count
/// @return Error code
@ffi.Native<ffi.UnsignedInt Function(mnn_interpreter_t, mnn_tensor_t, ffi.Pointer<ffi.Int>, ffi.Int)>(
  symbol: 'mnn_interpreter_resize_tensor',
)
external int _mnn_interpreter_resize_tensor(
  mnn_interpreter_t self$1,
  mnn_tensor_t tensor,
  ffi.Pointer<ffi.Int> dims,
  int dim_count,
);

ErrorCode mnn_interpreter_resize_tensor(
  mnn_interpreter_t self$1,
  mnn_tensor_t tensor,
  ffi.Pointer<ffi.Int> dims,
  int dim_count,
) => ErrorCode.fromValue(
  _mnn_interpreter_resize_tensor(
    self$1,
    tensor,
    dims,
    dim_count,
  ),
);

@ffi.Native<ffi.UnsignedInt Function(mnn_interpreter_t, mnn_tensor_t, ffi.Int, ffi.Int, ffi.Int, ffi.Int)>(
  symbol: 'mnn_interpreter_resize_tensor_1',
)
external int _mnn_interpreter_resize_tensor_1(
  mnn_interpreter_t self$1,
  mnn_tensor_t tensor,
  int batch,
  int channel,
  int height,
  int width,
);

ErrorCode mnn_interpreter_resize_tensor_1(
  mnn_interpreter_t self$1,
  mnn_tensor_t tensor,
  int batch,
  int channel,
  int height,
  int width,
) => ErrorCode.fromValue(
  _mnn_interpreter_resize_tensor_1(
    self$1,
    tensor,
    batch,
    channel,
    height,
    width,
  ),
);

/// @brief Run session
/// @param self Interpreter instance
/// @param session Session to run
/// @param callback Callback function to be called after run
/// @return Error code
@ffi.Native<ffi.UnsignedInt Function(mnn_interpreter_t, mnn_session_t, mnn_callback_0)>(
  symbol: 'mnn_interpreter_run_session',
)
external int _mnn_interpreter_run_session(
  mnn_interpreter_t self$1,
  mnn_session_t session,
  mnn_callback_0 callback,
);

ErrorCode mnn_interpreter_run_session(
  mnn_interpreter_t self$1,
  mnn_session_t session,
  mnn_callback_0 callback,
) => ErrorCode.fromValue(
  _mnn_interpreter_run_session(
    self$1,
    session,
    callback,
  ),
);

/// @brief Set cache file for interpreter
/// @param self Interpreter instance
/// @param cache_file Cache file path
/// @param key_size Key size
@ffi.Native<ffi.Void Function(mnn_interpreter_t, ffi.Pointer<ffi.Char>, ffi.Size)>()
external void mnn_interpreter_set_cache_file(
  mnn_interpreter_t self$1,
  ffi.Pointer<ffi.Char> cache_file,
  int key_size,
);

/// @brief Set external file for interpreter
/// @param self Interpreter instance
/// @param file External file path
/// @param flag Flag value
@ffi.Native<ffi.Void Function(mnn_interpreter_t, ffi.Pointer<ffi.Char>, ffi.Size)>()
external void mnn_interpreter_set_external_file(
  mnn_interpreter_t self$1,
  ffi.Pointer<ffi.Char> file,
  int flag,
);

/// @brief Set session hint
/// @param self Interpreter instance
/// @param mode Hint mode
/// @param value Hint value
@ffi.Native<ffi.Void Function(mnn_interpreter_t, ffi.Int, ffi.Int)>()
external void mnn_interpreter_set_session_hint(
  mnn_interpreter_t self$1,
  int mode,
  int value,
);

/// @brief Set session mode
/// @param self Interpreter instance
/// @param mode Session mode
@ffi.Native<ffi.Void Function(mnn_interpreter_t, ffi.Int)>()
external void mnn_interpreter_set_session_mode(
  mnn_interpreter_t self$1,
  int mode,
);

/// @brief Update cache file
/// @param self Interpreter instance
/// @param session Session
/// @param flag Flag value
/// @return Error code
@ffi.Native<ffi.UnsignedInt Function(mnn_interpreter_t, mnn_session_t, ffi.Int)>(
  symbol: 'mnn_interpreter_update_cache_file',
)
external int _mnn_interpreter_update_cache_file(
  mnn_interpreter_t self$1,
  mnn_session_t session,
  int flag,
);

ErrorCode mnn_interpreter_update_cache_file(
  mnn_interpreter_t self$1,
  mnn_session_t session,
  int flag,
) => ErrorCode.fromValue(
  _mnn_interpreter_update_cache_file(
    self$1,
    session,
    flag,
  ),
);

/// @brief Update session to model
/// @param self Interpreter instance
/// @param session Session
/// @return Error code
@ffi.Native<ffi.UnsignedInt Function(mnn_interpreter_t, mnn_session_t)>(
  symbol: 'mnn_interpreter_update_session_to_model',
)
external int _mnn_interpreter_update_session_to_model(
  mnn_interpreter_t self$1,
  mnn_session_t session,
);

ErrorCode mnn_interpreter_update_session_to_model(
  mnn_interpreter_t self$1,
  mnn_session_t session,
) => ErrorCode.fromValue(
  _mnn_interpreter_update_session_to_model(
    self$1,
    session,
  ),
);

/// @brief Get uuid from interpreter
/// @param self Interpreter instance
/// @return Uuid string or NULL if failed
@ffi.Native<ffi.Pointer<ffi.Char> Function(mnn_interpreter_t)>(isLeaf: true)
external ffi.Pointer<ffi.Char> mnn_interpreter_uuid(
  mnn_interpreter_t self$1,
);

@ffi.Native<ffi.Int Function(mnn_module_t, VARP_t)>()
external int mnn_module_add_parameter(
  mnn_module_t self$1,
  VARP_t parameter,
);

@ffi.Native<ffi.Void Function(mnn_module_t)>()
external void mnn_module_clear_cache(
  mnn_module_t self$1,
);

@ffi.Native<mnn_module_t Function(mnn_module_t, ffi.Bool)>()
external mnn_module_t mnn_module_clone(
  mnn_module_t self$1,
  bool share_params,
);

@ffi.Native<ffi.Void Function(mnn_module_t)>()
external void mnn_module_destroy(
  mnn_module_t self$1,
);

@ffi.Native<mnn_module_t Function(VecVARP_t, VecVARP_t, ffi.Bool)>()
external mnn_module_t mnn_module_extract(
  VecVARP_t inputs,
  VecVARP_t outputs,
  bool fortrain,
);

@ffi.Native<ffi.UnsignedInt Function(mnn_module_t, VARP_t, ffi.Pointer<VARP_t>, mnn_callback_0)>(
  symbol: 'mnn_module_forward',
)
external int _mnn_module_forward(
  mnn_module_t self$1,
  VARP_t input,
  ffi.Pointer<VARP_t> output,
  mnn_callback_0 callback,
);

ErrorCode mnn_module_forward(
  mnn_module_t self$1,
  VARP_t input,
  ffi.Pointer<VARP_t> output,
  mnn_callback_0 callback,
) => ErrorCode.fromValue(
  _mnn_module_forward(
    self$1,
    input,
    output,
    callback,
  ),
);

@ffi.Native<mnn_module_info_t Function(mnn_module_t)>()
external mnn_module_info_t mnn_module_get_info(
  mnn_module_t self$1,
);

@ffi.Native<ffi.Bool Function(mnn_module_t)>()
external bool mnn_module_get_is_training(
  mnn_module_t self$1,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(mnn_module_t)>()
external ffi.Pointer<ffi.Char> mnn_module_get_name(
  mnn_module_t self$1,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(mnn_module_t)>()
external ffi.Pointer<ffi.Char> mnn_module_get_type(
  mnn_module_t self$1,
);

/// MNN::Express::Module::Info
@ffi.Native<mnn_module_info_t Function()>()
external mnn_module_info_t mnn_module_info_create();

@ffi.Native<ffi.Void Function(mnn_module_info_t)>()
external void mnn_module_info_destroy(
  mnn_module_info_t self$1,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(mnn_module_info_t)>()
external ffi.Pointer<ffi.Char> mnn_module_info_get_bizCode(
  mnn_module_info_t self$1,
);

@ffi.Native<ffi.Int Function(mnn_module_info_t)>()
external int mnn_module_info_get_default_format(
  mnn_module_info_t self$1,
);

@ffi.Native<ffi.Size Function(mnn_module_info_t, ffi.Pointer<ffi.Pointer<ffi.Char>>)>()
external int mnn_module_info_get_input_names(
  mnn_module_info_t self$1,
  ffi.Pointer<ffi.Pointer<ffi.Char>> input_names,
);

@ffi.Native<ffi.Pointer<mnn_expr_Variable_Info> Function(mnn_module_info_t, ffi.Int)>()
external ffi.Pointer<mnn_expr_Variable_Info> mnn_module_info_get_inputs_at(
  mnn_module_info_t self$1,
  int index,
);

@ffi.Native<ffi.Size Function(mnn_module_info_t)>()
external int mnn_module_info_get_inputs_length(
  mnn_module_info_t self$1,
);

@ffi.Native<
  ffi.Size Function(mnn_module_info_t, ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Pointer<ffi.Pointer<ffi.Char>>)
>()
external int mnn_module_info_get_metadata(
  mnn_module_info_t self$1,
  ffi.Pointer<ffi.Pointer<ffi.Char>> keys,
  ffi.Pointer<ffi.Pointer<ffi.Char>> values,
);

@ffi.Native<ffi.Size Function(mnn_module_info_t, ffi.Pointer<ffi.Pointer<ffi.Char>>)>()
external int mnn_module_info_get_output_names(
  mnn_module_info_t self$1,
  ffi.Pointer<ffi.Pointer<ffi.Char>> output_names,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(mnn_module_info_t)>()
external ffi.Pointer<ffi.Char> mnn_module_info_get_uuid(
  mnn_module_info_t self$1,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(mnn_module_info_t)>()
external ffi.Pointer<ffi.Char> mnn_module_info_get_version(
  mnn_module_info_t self$1,
);

@ffi.Native<
  mnn_module_t Function(
    ffi.Pointer<ffi.Uint8>,
    ffi.Size,
    ffi.Pointer<ffi.Pointer<ffi.Char>>,
    ffi.Int,
    ffi.Pointer<ffi.Pointer<ffi.Char>>,
    ffi.Int,
    mnn_runtime_manager_t,
    ffi.Pointer<mnn_module_config_t>,
  )
>()
external mnn_module_t mnn_module_load_from_bytes(
  ffi.Pointer<ffi.Uint8> buffer,
  int length,
  ffi.Pointer<ffi.Pointer<ffi.Char>> inputs,
  int input_count,
  ffi.Pointer<ffi.Pointer<ffi.Char>> outputs,
  int output_count,
  mnn_runtime_manager_t mgr,
  ffi.Pointer<mnn_module_config_t> config,
);

/// Module API
/// inputs and outputs are arrays of strings (char**), length is input_count/output_count
@ffi.Native<
  mnn_module_t Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Pointer<ffi.Char>>,
    ffi.Int,
    ffi.Pointer<ffi.Pointer<ffi.Char>>,
    ffi.Int,
    mnn_runtime_manager_t,
    ffi.Pointer<mnn_module_config_t>,
  )
>()
external mnn_module_t mnn_module_load_from_file(
  ffi.Pointer<ffi.Char> file_name,
  ffi.Pointer<ffi.Pointer<ffi.Char>> inputs,
  int input_count,
  ffi.Pointer<ffi.Pointer<ffi.Char>> outputs,
  int output_count,
  mnn_runtime_manager_t mgr,
  ffi.Pointer<mnn_module_config_t> config,
);

@ffi.Native<ffi.Bool Function(mnn_module_t, VecVARP_t)>()
external bool mnn_module_load_parameters(
  mnn_module_t self$1,
  VecVARP_t parameters,
);

@ffi.Native<ffi.UnsignedInt Function(mnn_module_t, VecVARP_t, ffi.Pointer<VecVARP_t>, mnn_callback_0)>(
  symbol: 'mnn_module_on_forward',
)
external int _mnn_module_on_forward(
  mnn_module_t self$1,
  VecVARP_t inputs,
  ffi.Pointer<VecVARP_t> outputs,
  mnn_callback_0 callback,
);

ErrorCode mnn_module_on_forward(
  mnn_module_t self$1,
  VecVARP_t inputs,
  ffi.Pointer<VecVARP_t> outputs,
  mnn_callback_0 callback,
) => ErrorCode.fromValue(
  _mnn_module_on_forward(
    self$1,
    inputs,
    outputs,
    callback,
  ),
);

@ffi.Native<ffi.Void Function(mnn_module_t, ffi.Bool)>()
external void mnn_module_set_is_training(
  mnn_module_t self$1,
  bool is_training,
);

@ffi.Native<ffi.Void Function(mnn_module_t, ffi.Pointer<ffi.Char>)>()
external void mnn_module_set_name(
  mnn_module_t self$1,
  ffi.Pointer<ffi.Char> name,
);

@ffi.Native<ffi.Void Function(mnn_module_t, VARP_t, ffi.Int)>()
external void mnn_module_set_parameter(
  mnn_module_t self$1,
  VARP_t parameter,
  int index,
);

@ffi.Native<ffi.Void Function(mnn_module_t, ffi.Pointer<ffi.Char>)>()
external void mnn_module_set_type(
  mnn_module_t self$1,
  ffi.Pointer<ffi.Char> type,
);

/// @brief Destroy runtime info
/// @param runtime Runtime info to destroy
@ffi.Native<ffi.Void Function(mnn_runtime_info_t)>()
external void mnn_runtime_info_destroy(
  mnn_runtime_info_t runtime,
);

/// RuntimeManager API
@ffi.Native<mnn_runtime_manager_t Function(mnn_schedule_config_t)>()
external mnn_runtime_manager_t mnn_runtime_manager_create(
  mnn_schedule_config_t config,
);

@ffi.Native<ffi.Void Function(mnn_runtime_manager_t)>()
external void mnn_runtime_manager_destroy(
  mnn_runtime_manager_t self$1,
);

@ffi.Native<ffi.Bool Function(mnn_runtime_manager_t, ffi.Int, ffi.Pointer<ffi.Void>)>()
external bool mnn_runtime_manager_get_info(
  mnn_runtime_manager_t self$1,
  int code,
  ffi.Pointer<ffi.Void> ptr,
);

@ffi.Native<ffi.Bool Function(mnn_runtime_manager_t, ffi.Int)>()
external bool mnn_runtime_manager_is_backend_support(
  mnn_runtime_manager_t self$1,
  int backend,
);

@ffi.Native<ffi.Void Function(mnn_runtime_manager_t, ffi.Pointer<ffi.Char>)>()
external void mnn_runtime_manager_set_cache(
  mnn_runtime_manager_t self$1,
  ffi.Pointer<ffi.Char> cache_path,
);

@ffi.Native<ffi.Void Function(mnn_runtime_manager_t, ffi.Pointer<ffi.Char>)>()
external void mnn_runtime_manager_set_external_file(
  mnn_runtime_manager_t self$1,
  ffi.Pointer<ffi.Char> path,
);

@ffi.Native<ffi.Void Function(mnn_runtime_manager_t, ffi.Pointer<ffi.Char>, ffi.Int)>()
external void mnn_runtime_manager_set_external_path(
  mnn_runtime_manager_t self$1,
  ffi.Pointer<ffi.Char> external_path,
  int type,
);

@ffi.Native<ffi.Void Function(mnn_runtime_manager_t, ffi.Int, ffi.Int)>()
external void mnn_runtime_manager_set_hint(
  mnn_runtime_manager_t self$1,
  int mode,
  int value,
);

@ffi.Native<ffi.Void Function(mnn_runtime_manager_t, ffi.Int)>()
external void mnn_runtime_manager_set_mode(
  mnn_runtime_manager_t self$1,
  int mode,
);

@ffi.Native<ffi.Bool Function(ffi.Pointer<ffi.Char>, ffi.Int, ffi.Pointer<ffi.Pointer<ffi.Char>>)>()
external bool mnn_runtime_manager_static_get_device_info(
  ffi.Pointer<ffi.Char> device_key,
  int type,
  ffi.Pointer<ffi.Pointer<ffi.Char>> device_value,
);

@ffi.Native<ffi.Void Function(mnn_runtime_manager_t)>()
external void mnn_runtime_manager_update_cache(
  mnn_runtime_manager_t self$1,
);

/// @brief Get tensor batch
/// @param self Tensor
/// @return Batch
@ffi.Native<ffi.Int Function(mnn_tensor_t)>(isLeaf: true)
external int mnn_tensor_batch(
  mnn_tensor_t self$1,
);

/// @brief Get buffer
/// @param self Tensor
/// @return Buffer pointer
@ffi.Native<ffi.Pointer<halide_buffer_c_t> Function(mnn_tensor_t)>(isLeaf: true)
external ffi.Pointer<halide_buffer_c_t> mnn_tensor_buffer(
  mnn_tensor_t self$1,
);

/// @brief Get tensor channel
/// @param self Tensor
/// @return Channel
@ffi.Native<ffi.Int Function(mnn_tensor_t)>(isLeaf: true)
external int mnn_tensor_channel(
  mnn_tensor_t self$1,
);

/// @brief Clone tensor
/// @param src Source tensor
/// @param deep_copy Whether to perform deep copy
/// @return Cloned tensor or NULL if failed
@ffi.Native<mnn_tensor_t Function(mnn_tensor_t, ffi.Bool)>()
external mnn_tensor_t mnn_tensor_clone(
  mnn_tensor_t src,
  bool deep_copy,
);

/// @brief Copy data from host tensor
/// @param self Target tensor
/// @param host_tensor Source tensor
/// @return Error code
@ffi.Native<ffi.UnsignedInt Function(mnn_tensor_t, mnn_tensor_t)>(symbol: 'mnn_tensor_copy_from_host')
external int _mnn_tensor_copy_from_host(
  mnn_tensor_t self$1,
  mnn_tensor_t host_tensor,
);

ErrorCode mnn_tensor_copy_from_host(
  mnn_tensor_t self$1,
  mnn_tensor_t host_tensor,
) => ErrorCode.fromValue(
  _mnn_tensor_copy_from_host(
    self$1,
    host_tensor,
  ),
);

/// @brief Copy data to host tensor
/// @param self Source tensor
/// @param host_tensor Target tensor
/// @return Error code
@ffi.Native<ffi.UnsignedInt Function(mnn_tensor_t, mnn_tensor_t)>(symbol: 'mnn_tensor_copy_to_host')
external int _mnn_tensor_copy_to_host(
  mnn_tensor_t self$1,
  mnn_tensor_t host_tensor,
);

ErrorCode mnn_tensor_copy_to_host(
  mnn_tensor_t self$1,
  mnn_tensor_t host_tensor,
) => ErrorCode.fromValue(
  _mnn_tensor_copy_to_host(
    self$1,
    host_tensor,
  ),
);

/// @brief Create tensor with dimension size and type
/// @param dim_size Dimension size
/// @param type Dimension type
/// @return Tensor instance or NULL if failed
@ffi.Native<mnn_tensor_t Function(ffi.Int, ffi.UnsignedInt)>(symbol: 'mnn_tensor_create')
external mnn_tensor_t _mnn_tensor_create(
  int dim_size,
  int type,
);

mnn_tensor_t mnn_tensor_create(
  int dim_size,
  DimensionType type,
) => _mnn_tensor_create(
  dim_size,
  type.value,
);

/// @brief Create device tensor
/// @param shape Tensor shape array
/// @param shape_size Shape array size
/// @param type Data type
/// @param dim_type Dimension type
/// @return Tensor instance or NULL if failed
@ffi.Native<mnn_tensor_t Function(ffi.Pointer<ffi.Int>, ffi.Int, halide_type_c_t, ffi.UnsignedInt)>(
  symbol: 'mnn_tensor_create_device',
)
external mnn_tensor_t _mnn_tensor_create_device(
  ffi.Pointer<ffi.Int> shape,
  int shape_size,
  halide_type_c_t type,
  int dim_type,
);

mnn_tensor_t mnn_tensor_create_device(
  ffi.Pointer<ffi.Int> shape,
  int shape_size,
  halide_type_c_t type,
  DimensionType dim_type,
) => _mnn_tensor_create_device(
  shape,
  shape_size,
  type,
  dim_type.value,
);

/// @brief Create tensor with same shape as given tensor
/// @param self Shape provider
/// @param type Dimension type
/// @param alloc_memory Whether allocate memory
/// @return Tensor instance or NULL if failed
@ffi.Native<mnn_tensor_t Function(mnn_tensor_t, ffi.UnsignedInt, ffi.Bool)>(
  symbol: 'mnn_tensor_create_from_tensor',
)
external mnn_tensor_t _mnn_tensor_create_from_tensor(
  mnn_tensor_t self$1,
  int type,
  bool alloc_memory,
);

mnn_tensor_t mnn_tensor_create_from_tensor(
  mnn_tensor_t self$1,
  DimensionType type,
  bool alloc_memory,
) => _mnn_tensor_create_from_tensor(
  self$1,
  type.value,
  alloc_memory,
);

/// @brief Create tensor with data
/// @param shape Tensor shape array
/// @param shape_size Shape array size
/// @param type Data type
/// @param data Data pointer
/// @param dim_type Dimension type
/// @return Tensor instance or NULL if failed
@ffi.Native<
  mnn_tensor_t Function(
    ffi.Pointer<ffi.Int>,
    ffi.Int,
    halide_type_c_t,
    ffi.Pointer<ffi.Void>,
    ffi.UnsignedInt,
  )
>(symbol: 'mnn_tensor_create_with_data')
external mnn_tensor_t _mnn_tensor_create_with_data(
  ffi.Pointer<ffi.Int> shape,
  int shape_size,
  halide_type_c_t type,
  ffi.Pointer<ffi.Void> data,
  int dim_type,
);

mnn_tensor_t mnn_tensor_create_with_data(
  ffi.Pointer<ffi.Int> shape,
  int shape_size,
  halide_type_c_t type,
  ffi.Pointer<ffi.Void> data,
  DimensionType dim_type,
) => _mnn_tensor_create_with_data(
  shape,
  shape_size,
  type,
  data,
  dim_type.value,
);

/// @brief Destroy tensor
/// @param tensor Tensor to destroy
@ffi.Native<ffi.Void Function(mnn_tensor_t)>(isLeaf: true)
external void mnn_tensor_destroy(
  mnn_tensor_t tensor,
);

/// @brief Get device ID
/// @param self Tensor
/// @return Device ID
@ffi.Native<ffi.Uint64 Function(mnn_tensor_t)>(isLeaf: true)
external int mnn_tensor_device_id(
  mnn_tensor_t self$1,
);

/// @brief Get tensor dimensions
/// @param self Tensor
/// @return Dimension count
@ffi.Native<ffi.Int Function(mnn_tensor_t)>(isLeaf: true)
external int mnn_tensor_dimensions(
  mnn_tensor_t self$1,
);

/// @brief Get tensor element count
/// @param self Tensor
/// @return Element count
@ffi.Native<ffi.Int Function(mnn_tensor_t)>(isLeaf: true)
external int mnn_tensor_element_size(
  mnn_tensor_t self$1,
);

/// @brief Get dimension type
/// @param self Tensor
/// @return Dimension type
@ffi.Native<ffi.UnsignedInt Function(mnn_tensor_t)>(symbol: 'mnn_tensor_get_dimension_type', isLeaf: true)
external int _mnn_tensor_get_dimension_type(
  mnn_tensor_t self$1,
);

DimensionType mnn_tensor_get_dimension_type(
  mnn_tensor_t self$1,
) => DimensionType.fromValue(
  _mnn_tensor_get_dimension_type(
    self$1,
  ),
);

/// @brief Get handle data type
/// @param self Tensor
/// @return Handle data type
@ffi.Native<ffi.UnsignedInt Function(mnn_tensor_t)>(symbol: 'mnn_tensor_get_handle_data_type', isLeaf: true)
external int _mnn_tensor_get_handle_data_type(
  mnn_tensor_t self$1,
);

HandleDataType mnn_tensor_get_handle_data_type(
  mnn_tensor_t self$1,
) => HandleDataType.fromValue(
  _mnn_tensor_get_handle_data_type(
    self$1,
  ),
);

/// @brief Get data type
/// @param self Tensor
/// @return Data type
@ffi.Native<ffi.Pointer<halide_type_c_t> Function(mnn_tensor_t)>(isLeaf: true)
external ffi.Pointer<halide_type_c_t> mnn_tensor_get_type(
  mnn_tensor_t self$1,
);

/// @brief Get tensor height
/// @param self Tensor
/// @return Height
@ffi.Native<ffi.Int Function(mnn_tensor_t)>(isLeaf: true)
external int mnn_tensor_height(
  mnn_tensor_t self$1,
);

/// @brief Get host data pointer
/// @param self Tensor
/// @return Data pointer or NULL
@ffi.Native<ffi.Pointer<ffi.Void> Function(mnn_tensor_t)>(isLeaf: true)
external ffi.Pointer<ffi.Void> mnn_tensor_host(
  mnn_tensor_t self$1,
);

/// @brief Get tensor length
/// @param self Tensor
/// @param index Dimension index
/// @return Length
@ffi.Native<ffi.Int Function(mnn_tensor_t, ffi.Int)>(isLeaf: true)
external int mnn_tensor_length(
  mnn_tensor_t self$1,
  int index,
);

/// @brief Map tensor for access
/// @param self Tensor
/// @param mtype Map type
/// @param dtype Dimension type
/// @return Mapped pointer or NULL
@ffi.Native<ffi.Pointer<ffi.Void> Function(mnn_tensor_t, ffi.UnsignedInt, ffi.UnsignedInt)>(
  symbol: 'mnn_tensor_map',
  isLeaf: true,
)
external ffi.Pointer<ffi.Void> _mnn_tensor_map(
  mnn_tensor_t self$1,
  int mtype,
  int dtype,
);

ffi.Pointer<ffi.Void> mnn_tensor_map(
  mnn_tensor_t self$1,
  MapType mtype,
  DimensionType dtype,
) => _mnn_tensor_map(
  self$1,
  mtype.value,
  dtype.value,
);

@ffi.Native<ffi.Void Function(mnn_tensor_t)>()
external void mnn_tensor_print(
  mnn_tensor_t self$1,
);

@ffi.Native<ffi.Void Function(mnn_tensor_t)>()
external void mnn_tensor_print_shape(
  mnn_tensor_t self$1,
);

/// @brief Set device pointer
/// @param self Tensor
/// @param device_ptr Device pointer
/// @param memory_type Memory type
/// @return Error code
@ffi.Native<ffi.UnsignedInt Function(mnn_tensor_t, ffi.Pointer<ffi.Void>, ffi.Int)>(
  symbol: 'mnn_tensor_set_device_ptr',
  isLeaf: true,
)
external int _mnn_tensor_set_device_ptr(
  mnn_tensor_t self$1,
  ffi.Pointer<ffi.Void> device_ptr,
  int memory_type,
);

ErrorCode mnn_tensor_set_device_ptr(
  mnn_tensor_t self$1,
  ffi.Pointer<ffi.Void> device_ptr,
  int memory_type,
) => ErrorCode.fromValue(
  _mnn_tensor_set_device_ptr(
    self$1,
    device_ptr,
    memory_type,
  ),
);

@ffi.Native<
  ffi.UnsignedInt Function(mnn_tensor_t, ffi.Int, ffi.Pointer<ffi.Float>, ffi.Int, ffi.Int, ffi.Int)
>(symbol: 'mnn_tensor_set_image_f32', isLeaf: true)
external int _mnn_tensor_set_image_f32(
  mnn_tensor_t self$1,
  int index,
  ffi.Pointer<ffi.Float> data,
  int width,
  int height,
  int channel,
);

ErrorCode mnn_tensor_set_image_f32(
  mnn_tensor_t self$1,
  int index,
  ffi.Pointer<ffi.Float> data,
  int width,
  int height,
  int channel,
) => ErrorCode.fromValue(
  _mnn_tensor_set_image_f32(
    self$1,
    index,
    data,
    width,
    height,
    channel,
  ),
);

/// @brief Set tensor length
/// @param self Tensor
/// @param index Dimension index
/// @param length Length value
@ffi.Native<ffi.Void Function(mnn_tensor_t, ffi.Int, ffi.Int)>(isLeaf: true)
external void mnn_tensor_set_length(
  mnn_tensor_t self$1,
  int index,
  int length,
);

/// @brief Set tensor stride
/// @param self Tensor
/// @param index Dimension index
/// @param stride Stride value
@ffi.Native<ffi.Void Function(mnn_tensor_t, ffi.Int, ffi.Int)>(isLeaf: true)
external void mnn_tensor_set_stride(
  mnn_tensor_t self$1,
  int index,
  int stride,
);

/// @brief Set data type
/// @param self Tensor
/// @param type Data type
@ffi.Native<ffi.Void Function(mnn_tensor_t, ffi.Int)>(isLeaf: true)
external void mnn_tensor_set_type(
  mnn_tensor_t self$1,
  int type,
);

/// @brief Get tensor shape
/// @param self Tensor
/// @param shape Output shape array (must be pre-allocated)
/// @param shape_size Shape array size
/// @return Error code
@ffi.Native<ffi.UnsignedInt Function(mnn_tensor_t, ffi.Pointer<ffi.Int>, ffi.Int)>(
  symbol: 'mnn_tensor_shape',
  isLeaf: true,
)
external int _mnn_tensor_shape(
  mnn_tensor_t self$1,
  ffi.Pointer<ffi.Int> shape,
  int shape_size,
);

ErrorCode mnn_tensor_shape(
  mnn_tensor_t self$1,
  ffi.Pointer<ffi.Int> shape,
  int shape_size,
) => ErrorCode.fromValue(
  _mnn_tensor_shape(
    self$1,
    shape,
    shape_size,
  ),
);

/// @brief Get tensor data size in bytes
/// @param self Tensor
/// @return Size in bytes
@ffi.Native<ffi.Int Function(mnn_tensor_t)>(isLeaf: true)
external int mnn_tensor_size(
  mnn_tensor_t self$1,
);

/// @brief Get tensor stride
/// @param self Tensor
/// @param index Dimension index
/// @return Stride
@ffi.Native<ffi.Int Function(mnn_tensor_t, ffi.Int)>(isLeaf: true)
external int mnn_tensor_stride(
  mnn_tensor_t self$1,
  int index,
);

/// @brief Unmap tensor
/// @param self Tensor
/// @param mtype Map type
/// @param dtype Dimension type
/// @param map_ptr Mapped pointer
@ffi.Native<ffi.Void Function(mnn_tensor_t, ffi.UnsignedInt, ffi.UnsignedInt, ffi.Pointer<ffi.Void>)>(
  symbol: 'mnn_tensor_unmap',
  isLeaf: true,
)
external void _mnn_tensor_unmap(
  mnn_tensor_t self$1,
  int mtype,
  int dtype,
  ffi.Pointer<ffi.Void> map_ptr,
);

void mnn_tensor_unmap(
  mnn_tensor_t self$1,
  MapType mtype,
  DimensionType dtype,
  ffi.Pointer<ffi.Void> map_ptr,
) => _mnn_tensor_unmap(
  self$1,
  mtype.value,
  dtype.value,
  map_ptr,
);

/// @brief Get tensor shape in bytes (unsigned)
/// @param self Tensor
/// @return Size in bytes
@ffi.Native<ffi.Size Function(mnn_tensor_t)>(isLeaf: true)
external int mnn_tensor_usize(
  mnn_tensor_t self$1,
);

/// @brief Wait for tensor ready
/// @param self Tensor
/// @param mtype Map type
/// @param finish Whether wait for finish
/// @return Error code
@ffi.Native<ffi.UnsignedInt Function(mnn_tensor_t, ffi.UnsignedInt, ffi.Bool)>(symbol: 'mnn_tensor_wait')
external int _mnn_tensor_wait(
  mnn_tensor_t self$1,
  int mtype,
  bool finish,
);

ErrorCode mnn_tensor_wait(
  mnn_tensor_t self$1,
  MapType mtype,
  bool finish,
) => ErrorCode.fromValue(
  _mnn_tensor_wait(
    self$1,
    mtype.value,
    finish,
  ),
);

/// @brief Get tensor width
/// @param self Tensor
/// @return Width
@ffi.Native<ffi.Int Function(mnn_tensor_t)>(isLeaf: true)
external int mnn_tensor_width(
  mnn_tensor_t self$1,
);

/// @brief Creates a new timer instance
/// @return Pointer to the newly created timer
@ffi.Native<mnn_timer_t Function()>()
external mnn_timer_t mnn_timer_create();

/// @brief Gets the current time value from timer
/// @param timer Timer instance to query
/// @return Current time value
@ffi.Native<ffi.Uint64 Function(mnn_timer_t)>()
external int mnn_timer_current(
  mnn_timer_t timer,
);

/// @brief Destroys a timer instance
/// @param timer Timer instance to destroy
@ffi.Native<ffi.Void Function(mnn_timer_t)>()
external void mnn_timer_destroy(
  mnn_timer_t timer,
);

/// @brief Gets the duration in microseconds since last reset
/// @param timer Timer instance to query
/// @return Duration in microseconds
@ffi.Native<ffi.Uint64 Function(mnn_timer_t)>()
external int mnn_timer_duration_us(
  mnn_timer_t timer,
);

/// @brief Resets the timer to current time
/// @param timer Timer instance to reset
@ffi.Native<ffi.Void Function(mnn_timer_t)>()
external void mnn_timer_reset(
  mnn_timer_t timer,
);

/// indicate whether we should process iphone images back to canonical format,
/// or just pass them through "as-is"
@ffi.Native<ffi.Void Function(ffi.Int)>()
external void stbi_convert_iphone_png_to_rgb(
  int flag_true_if_should_convert,
);

@ffi.Native<ffi.Void Function(ffi.Int)>()
external void stbi_convert_iphone_png_to_rgb_thread(
  int flag_true_if_should_convert,
);

/// get a VERY brief reason for failure
/// on most compilers (and ALL modern mainstream compilers) this is threadsafe
@ffi.Native<ffi.Pointer<ffi.Char> Function()>()
external ffi.Pointer<ffi.Char> stbi_failure_reason();

@ffi.Native<ffi.Void Function(ffi.Int)>()
external void stbi_flip_vertically_on_write(
  int flip_boolean,
);

@ffi.Native<ffi.Void Function(ffi.Float)>()
external void stbi_hdr_to_ldr_gamma(
  double gamma,
);

@ffi.Native<ffi.Void Function(ffi.Float)>()
external void stbi_hdr_to_ldr_scale(
  double scale,
);

/// free the loaded image -- this is just free()
@ffi.Native<ffi.Void Function(ffi.Pointer<ffi.Void>)>()
external void stbi_image_free(
  ffi.Pointer<ffi.Void> retval_from_stbi_load,
);

@ffi.Native<
  ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Int>, ffi.Pointer<ffi.Int>, ffi.Pointer<ffi.Int>)
>()
external int stbi_info(
  ffi.Pointer<ffi.Char> filename,
  ffi.Pointer<ffi.Int> x,
  ffi.Pointer<ffi.Int> y,
  ffi.Pointer<ffi.Int> comp,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<stbi_io_callbacks>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
  )
>()
external int stbi_info_from_callbacks(
  ffi.Pointer<stbi_io_callbacks> clbk,
  ffi.Pointer<ffi.Void> user,
  ffi.Pointer<ffi.Int> x,
  ffi.Pointer<ffi.Int> y,
  ffi.Pointer<ffi.Int> comp,
);

@ffi.Native<
  ffi.Int Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Int>, ffi.Pointer<ffi.Int>, ffi.Pointer<ffi.Int>)
>()
external int stbi_info_from_file(
  ffi.Pointer<FILE> f,
  ffi.Pointer<ffi.Int> x,
  ffi.Pointer<ffi.Int> y,
  ffi.Pointer<ffi.Int> comp,
);

/// get image dimensions & components without fully decoding
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<stbi_uc>,
    ffi.Int,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
  )
>()
external int stbi_info_from_memory(
  ffi.Pointer<stbi_uc> buffer,
  int len,
  ffi.Pointer<ffi.Int> x,
  ffi.Pointer<ffi.Int> y,
  ffi.Pointer<ffi.Int> comp,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<ffi.Char>)>()
external int stbi_is_16_bit(
  ffi.Pointer<ffi.Char> filename,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<stbi_io_callbacks>, ffi.Pointer<ffi.Void>)>()
external int stbi_is_16_bit_from_callbacks(
  ffi.Pointer<stbi_io_callbacks> clbk,
  ffi.Pointer<ffi.Void> user,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<FILE>)>()
external int stbi_is_16_bit_from_file(
  ffi.Pointer<FILE> f,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<stbi_uc>, ffi.Int)>()
external int stbi_is_16_bit_from_memory(
  ffi.Pointer<stbi_uc> buffer,
  int len,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<ffi.Char>)>()
external int stbi_is_hdr(
  ffi.Pointer<ffi.Char> filename,
);

/// stbi_is_hdr is always defined, but always returns false if STBI_NO_HDR
@ffi.Native<ffi.Int Function(ffi.Pointer<stbi_io_callbacks>, ffi.Pointer<ffi.Void>)>()
external int stbi_is_hdr_from_callbacks(
  ffi.Pointer<stbi_io_callbacks> clbk,
  ffi.Pointer<ffi.Void> user,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<FILE>)>()
external int stbi_is_hdr_from_file(
  ffi.Pointer<FILE> f,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<stbi_uc>, ffi.Int)>()
external int stbi_is_hdr_from_memory(
  ffi.Pointer<stbi_uc> buffer,
  int len,
);

@ffi.Native<ffi.Void Function(ffi.Float)>()
external void stbi_ldr_to_hdr_gamma(
  double gamma,
);

@ffi.Native<ffi.Void Function(ffi.Float)>()
external void stbi_ldr_to_hdr_scale(
  double scale,
);

@ffi.Native<
  ffi.Pointer<stbi_uc> Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
  )
>()
external ffi.Pointer<stbi_uc> stbi_load(
  ffi.Pointer<ffi.Char> filename,
  ffi.Pointer<ffi.Int> x,
  ffi.Pointer<ffi.Int> y,
  ffi.Pointer<ffi.Int> channels_in_file,
  int desired_channels,
);

@ffi.Native<
  ffi.Pointer<stbi_us> Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
  )
>()
external ffi.Pointer<stbi_us> stbi_load_16(
  ffi.Pointer<ffi.Char> filename,
  ffi.Pointer<ffi.Int> x,
  ffi.Pointer<ffi.Int> y,
  ffi.Pointer<ffi.Int> channels_in_file,
  int desired_channels,
);

@ffi.Native<
  ffi.Pointer<stbi_us> Function(
    ffi.Pointer<stbi_io_callbacks>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
  )
>()
external ffi.Pointer<stbi_us> stbi_load_16_from_callbacks(
  ffi.Pointer<stbi_io_callbacks> clbk,
  ffi.Pointer<ffi.Void> user,
  ffi.Pointer<ffi.Int> x,
  ffi.Pointer<ffi.Int> y,
  ffi.Pointer<ffi.Int> channels_in_file,
  int desired_channels,
);

/// /////////////////////////////////
///
/// 16-bits-per-channel interface
@ffi.Native<
  ffi.Pointer<stbi_us> Function(
    ffi.Pointer<stbi_uc>,
    ffi.Int,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
  )
>()
external ffi.Pointer<stbi_us> stbi_load_16_from_memory(
  ffi.Pointer<stbi_uc> buffer,
  int len,
  ffi.Pointer<ffi.Int> x,
  ffi.Pointer<ffi.Int> y,
  ffi.Pointer<ffi.Int> channels_in_file,
  int desired_channels,
);

@ffi.Native<
  ffi.Pointer<stbi_uc> Function(
    ffi.Pointer<stbi_io_callbacks>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
  )
>()
external ffi.Pointer<stbi_uc> stbi_load_from_callbacks(
  ffi.Pointer<stbi_io_callbacks> clbk,
  ffi.Pointer<ffi.Void> user,
  ffi.Pointer<ffi.Int> x,
  ffi.Pointer<ffi.Int> y,
  ffi.Pointer<ffi.Int> channels_in_file,
  int desired_channels,
);

@ffi.Native<
  ffi.Pointer<stbi_uc> Function(
    ffi.Pointer<FILE>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
  )
>()
external ffi.Pointer<stbi_uc> stbi_load_from_file(
  ffi.Pointer<FILE> f,
  ffi.Pointer<ffi.Int> x,
  ffi.Pointer<ffi.Int> y,
  ffi.Pointer<ffi.Int> channels_in_file,
  int desired_channels,
);

@ffi.Native<
  ffi.Pointer<stbi_us> Function(
    ffi.Pointer<FILE>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
  )
>()
external ffi.Pointer<stbi_us> stbi_load_from_file_16(
  ffi.Pointer<FILE> f,
  ffi.Pointer<ffi.Int> x,
  ffi.Pointer<ffi.Int> y,
  ffi.Pointer<ffi.Int> channels_in_file,
  int desired_channels,
);

/// /////////////////////////////////
///
/// 8-bits-per-channel interface
@ffi.Native<
  ffi.Pointer<stbi_uc> Function(
    ffi.Pointer<stbi_uc>,
    ffi.Int,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
  )
>()
external ffi.Pointer<stbi_uc> stbi_load_from_memory(
  ffi.Pointer<stbi_uc> buffer,
  int len,
  ffi.Pointer<ffi.Int> x,
  ffi.Pointer<ffi.Int> y,
  ffi.Pointer<ffi.Int> channels_in_file,
  int desired_channels,
);

@ffi.Native<
  ffi.Pointer<stbi_uc> Function(
    ffi.Pointer<stbi_uc>,
    ffi.Int,
    ffi.Pointer<ffi.Pointer<ffi.Int>>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
  )
>()
external ffi.Pointer<stbi_uc> stbi_load_gif_from_memory(
  ffi.Pointer<stbi_uc> buffer,
  int len,
  ffi.Pointer<ffi.Pointer<ffi.Int>> delays,
  ffi.Pointer<ffi.Int> x,
  ffi.Pointer<ffi.Int> y,
  ffi.Pointer<ffi.Int> z,
  ffi.Pointer<ffi.Int> comp,
  int req_comp,
);

@ffi.Native<
  ffi.Pointer<ffi.Float> Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
  )
>()
external ffi.Pointer<ffi.Float> stbi_loadf(
  ffi.Pointer<ffi.Char> filename,
  ffi.Pointer<ffi.Int> x,
  ffi.Pointer<ffi.Int> y,
  ffi.Pointer<ffi.Int> channels_in_file,
  int desired_channels,
);

@ffi.Native<
  ffi.Pointer<ffi.Float> Function(
    ffi.Pointer<stbi_io_callbacks>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
  )
>()
external ffi.Pointer<ffi.Float> stbi_loadf_from_callbacks(
  ffi.Pointer<stbi_io_callbacks> clbk,
  ffi.Pointer<ffi.Void> user,
  ffi.Pointer<ffi.Int> x,
  ffi.Pointer<ffi.Int> y,
  ffi.Pointer<ffi.Int> channels_in_file,
  int desired_channels,
);

@ffi.Native<
  ffi.Pointer<ffi.Float> Function(
    ffi.Pointer<FILE>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
  )
>()
external ffi.Pointer<ffi.Float> stbi_loadf_from_file(
  ffi.Pointer<FILE> f,
  ffi.Pointer<ffi.Int> x,
  ffi.Pointer<ffi.Int> y,
  ffi.Pointer<ffi.Int> channels_in_file,
  int desired_channels,
);

@ffi.Native<
  ffi.Pointer<ffi.Float> Function(
    ffi.Pointer<stbi_uc>,
    ffi.Int,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
  )
>()
external ffi.Pointer<ffi.Float> stbi_loadf_from_memory(
  ffi.Pointer<stbi_uc> buffer,
  int len,
  ffi.Pointer<ffi.Int> x,
  ffi.Pointer<ffi.Int> y,
  ffi.Pointer<ffi.Int> channels_in_file,
  int desired_channels,
);

/// flip the image vertically, so the first pixel in the output array is the bottom left
@ffi.Native<ffi.Void Function(ffi.Int)>()
external void stbi_set_flip_vertically_on_load(
  int flag_true_if_should_flip,
);

@ffi.Native<ffi.Void Function(ffi.Int)>()
external void stbi_set_flip_vertically_on_load_thread(
  int flag_true_if_should_flip,
);

/// for image formats that explicitly notate that they have premultiplied alpha,
/// we just return the colors as stored in the file. set this flag to force
/// unpremultiplication. results are undefined if the unpremultiply overflow.
@ffi.Native<ffi.Void Function(ffi.Int)>()
external void stbi_set_unpremultiply_on_load(
  int flag_true_if_should_unpremultiply,
);

/// as above, but only applies to images loaded on the thread that calls the function
/// this function is only available if your compiler supports thread-local variables;
/// calling it will fail to link if your compiler doesn't
@ffi.Native<ffi.Void Function(ffi.Int)>()
external void stbi_set_unpremultiply_on_load_thread(
  int flag_true_if_should_unpremultiply,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Int, ffi.Int, ffi.Int, ffi.Pointer<ffi.Void>)>()
external int stbi_write_bmp(
  ffi.Pointer<ffi.Char> filename,
  int w,
  int h,
  int comp,
  ffi.Pointer<ffi.Void> data,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<stbi_write_func>,
    ffi.Pointer<ffi.Void>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Pointer<ffi.Void>,
  )
>()
external int stbi_write_bmp_to_func(
  ffi.Pointer<stbi_write_func> func,
  ffi.Pointer<ffi.Void> context,
  int w,
  int h,
  int comp,
  ffi.Pointer<ffi.Void> data,
);

@ffi.Native<ffi.Int>()
external int stbi_write_force_png_filter;

@ffi.Native<ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Int, ffi.Int, ffi.Int, ffi.Pointer<ffi.Float>)>()
external int stbi_write_hdr(
  ffi.Pointer<ffi.Char> filename,
  int w,
  int h,
  int comp,
  ffi.Pointer<ffi.Float> data,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<stbi_write_func>,
    ffi.Pointer<ffi.Void>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Pointer<ffi.Float>,
  )
>()
external int stbi_write_hdr_to_func(
  ffi.Pointer<stbi_write_func> func,
  ffi.Pointer<ffi.Void> context,
  int w,
  int h,
  int comp,
  ffi.Pointer<ffi.Float> data,
);

@ffi.Native<
  ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Int, ffi.Int, ffi.Int, ffi.Pointer<ffi.Void>, ffi.Int)
>()
external int stbi_write_jpg(
  ffi.Pointer<ffi.Char> filename,
  int x,
  int y,
  int comp,
  ffi.Pointer<ffi.Void> data,
  int quality,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<stbi_write_func>,
    ffi.Pointer<ffi.Void>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Pointer<ffi.Void>,
    ffi.Int,
  )
>()
external int stbi_write_jpg_to_func(
  ffi.Pointer<stbi_write_func> func,
  ffi.Pointer<ffi.Void> context,
  int x,
  int y,
  int comp,
  ffi.Pointer<ffi.Void> data,
  int quality,
);

@ffi.Native<
  ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Int, ffi.Int, ffi.Int, ffi.Pointer<ffi.Void>, ffi.Int)
>()
external int stbi_write_png(
  ffi.Pointer<ffi.Char> filename,
  int w,
  int h,
  int comp,
  ffi.Pointer<ffi.Void> data,
  int stride_in_bytes,
);

@ffi.Native<ffi.Int>()
external int stbi_write_png_compression_level;

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<stbi_write_func>,
    ffi.Pointer<ffi.Void>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Pointer<ffi.Void>,
    ffi.Int,
  )
>()
external int stbi_write_png_to_func(
  ffi.Pointer<stbi_write_func> func,
  ffi.Pointer<ffi.Void> context,
  int w,
  int h,
  int comp,
  ffi.Pointer<ffi.Void> data,
  int stride_in_bytes,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Int, ffi.Int, ffi.Int, ffi.Pointer<ffi.Void>)>()
external int stbi_write_tga(
  ffi.Pointer<ffi.Char> filename,
  int w,
  int h,
  int comp,
  ffi.Pointer<ffi.Void> data,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<stbi_write_func>,
    ffi.Pointer<ffi.Void>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Pointer<ffi.Void>,
  )
>()
external int stbi_write_tga_to_func(
  ffi.Pointer<stbi_write_func> func,
  ffi.Pointer<ffi.Void> context,
  int w,
  int h,
  int comp,
  ffi.Pointer<ffi.Void> data,
);

@ffi.Native<ffi.Int>()
external int stbi_write_tga_with_rle;

@ffi.Native<ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Int, ffi.Pointer<ffi.Char>, ffi.Int)>()
external int stbi_zlib_decode_buffer(
  ffi.Pointer<ffi.Char> obuffer,
  int olen,
  ffi.Pointer<ffi.Char> ibuffer,
  int ilen,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>, ffi.Int, ffi.Pointer<ffi.Int>)>()
external ffi.Pointer<ffi.Char> stbi_zlib_decode_malloc(
  ffi.Pointer<ffi.Char> buffer,
  int len,
  ffi.Pointer<ffi.Int> outlen,
);

/// ZLIB client - used by PNG, available for other purposes
@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>, ffi.Int, ffi.Int, ffi.Pointer<ffi.Int>)>()
external ffi.Pointer<ffi.Char> stbi_zlib_decode_malloc_guesssize(
  ffi.Pointer<ffi.Char> buffer,
  int len,
  int initial_size,
  ffi.Pointer<ffi.Int> outlen,
);

@ffi.Native<
  ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>, ffi.Int, ffi.Int, ffi.Pointer<ffi.Int>, ffi.Int)
>()
external ffi.Pointer<ffi.Char> stbi_zlib_decode_malloc_guesssize_headerflag(
  ffi.Pointer<ffi.Char> buffer,
  int len,
  int initial_size,
  ffi.Pointer<ffi.Int> outlen,
  int parse_header,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Int, ffi.Pointer<ffi.Char>, ffi.Int)>()
external int stbi_zlib_decode_noheader_buffer(
  ffi.Pointer<ffi.Char> obuffer,
  int olen,
  ffi.Pointer<ffi.Char> ibuffer,
  int ilen,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>, ffi.Int, ffi.Pointer<ffi.Int>)>()
external ffi.Pointer<ffi.Char> stbi_zlib_decode_noheader_malloc(
  ffi.Pointer<ffi.Char> buffer,
  int len,
  ffi.Pointer<ffi.Int> outlen,
);

/// This builds the samplers and does one allocation
@ffi.Native<ffi.Int Function(ffi.Pointer<STBIR_RESIZE>)>()
external int stbir_build_samplers(
  ffi.Pointer<STBIR_RESIZE> resize,
);

/// This will build samplers for threading.
/// You can pass in the number of threads you'd like to use (try_splits).
/// It returns the number of splits (threads) that you can call it with.
/// It might be less if the image resize can't be split up that many ways.
@ffi.Native<ffi.Int Function(ffi.Pointer<STBIR_RESIZE>, ffi.Int)>()
external int stbir_build_samplers_with_splits(
  ffi.Pointer<STBIR_RESIZE> resize,
  int try_splits,
);

/// You MUST call this, if you call stbir_build_samplers or stbir_build_samplers_with_splits
@ffi.Native<ffi.Void Function(ffi.Pointer<STBIR_RESIZE>)>()
external void stbir_free_samplers(
  ffi.Pointer<STBIR_RESIZE> resize,
);

/// medium api
@ffi.Native<
  ffi.Pointer<ffi.Void> Function(
    ffi.Pointer<ffi.Void>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Pointer<ffi.Void>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.UnsignedInt,
    ffi.UnsignedInt,
    ffi.UnsignedInt,
    ffi.UnsignedInt,
  )
>(symbol: 'stbir_resize')
external ffi.Pointer<ffi.Void> _stbir_resize(
  ffi.Pointer<ffi.Void> input_pixels,
  int input_w,
  int input_h,
  int input_stride_in_bytes,
  ffi.Pointer<ffi.Void> output_pixels,
  int output_w,
  int output_h,
  int output_stride_in_bytes,
  int pixel_layout,
  int data_type,
  int edge,
  int filter,
);

ffi.Pointer<ffi.Void> stbir_resize(
  ffi.Pointer<ffi.Void> input_pixels,
  int input_w,
  int input_h,
  int input_stride_in_bytes,
  ffi.Pointer<ffi.Void> output_pixels,
  int output_w,
  int output_h,
  int output_stride_in_bytes,
  StbirPixelLayout pixel_layout,
  StbirDataType data_type,
  StbirEdge edge,
  StbirFilter filter,
) => _stbir_resize(
  input_pixels,
  input_w,
  input_h,
  input_stride_in_bytes,
  output_pixels,
  output_w,
  output_h,
  output_stride_in_bytes,
  pixel_layout.value,
  data_type.value,
  edge.value,
  filter.value,
);

/// And this is the main function to perform the resize synchronously on one thread.
@ffi.Native<ffi.Int Function(ffi.Pointer<STBIR_RESIZE>)>()
external int stbir_resize_extended(
  ffi.Pointer<STBIR_RESIZE> resize,
);

/// Usually, you will always call stbir_resize_split with split_start as the thread_index
/// and "1" for the split_count.
/// But, if you have a weird situation where you MIGHT want 8 threads, but sometimes
/// only 4 threads, you can use 0,2,4,6 for the split_start's and use "2" for the
/// split_count each time to turn in into a 4 thread resize. (This is unusual).
@ffi.Native<ffi.Int Function(ffi.Pointer<STBIR_RESIZE>, ffi.Int, ffi.Int)>()
external int stbir_resize_extended_split(
  ffi.Pointer<STBIR_RESIZE> resize,
  int split_start,
  int split_count,
);

@ffi.Native<
  ffi.Pointer<ffi.Float> Function(
    ffi.Pointer<ffi.Float>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Pointer<ffi.Float>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.UnsignedInt,
  )
>(symbol: 'stbir_resize_float_linear')
external ffi.Pointer<ffi.Float> _stbir_resize_float_linear(
  ffi.Pointer<ffi.Float> input_pixels,
  int input_w,
  int input_h,
  int input_stride_in_bytes,
  ffi.Pointer<ffi.Float> output_pixels,
  int output_w,
  int output_h,
  int output_stride_in_bytes,
  int pixel_type,
);

ffi.Pointer<ffi.Float> stbir_resize_float_linear(
  ffi.Pointer<ffi.Float> input_pixels,
  int input_w,
  int input_h,
  int input_stride_in_bytes,
  ffi.Pointer<ffi.Float> output_pixels,
  int output_w,
  int output_h,
  int output_stride_in_bytes,
  StbirPixelLayout pixel_type,
) => _stbir_resize_float_linear(
  input_pixels,
  input_w,
  input_h,
  input_stride_in_bytes,
  output_pixels,
  output_w,
  output_h,
  output_stride_in_bytes,
  pixel_type.value,
);

/// First off, you must ALWAYS call stbir_resize_init on your resize structure before any of the other calls!
@ffi.Native<
  ffi.Void Function(
    ffi.Pointer<STBIR_RESIZE>,
    ffi.Pointer<ffi.Void>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Pointer<ffi.Void>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.UnsignedInt,
    ffi.UnsignedInt,
  )
>(symbol: 'stbir_resize_init')
external void _stbir_resize_init(
  ffi.Pointer<STBIR_RESIZE> resize,
  ffi.Pointer<ffi.Void> input_pixels,
  int input_w,
  int input_h,
  int input_stride_in_bytes,
  ffi.Pointer<ffi.Void> output_pixels,
  int output_w,
  int output_h,
  int output_stride_in_bytes,
  int pixel_layout,
  int data_type,
);

void stbir_resize_init(
  ffi.Pointer<STBIR_RESIZE> resize,
  ffi.Pointer<ffi.Void> input_pixels,
  int input_w,
  int input_h,
  int input_stride_in_bytes,
  ffi.Pointer<ffi.Void> output_pixels,
  int output_w,
  int output_h,
  int output_stride_in_bytes,
  StbirPixelLayout pixel_layout,
  StbirDataType data_type,
) => _stbir_resize_init(
  resize,
  input_pixels,
  input_w,
  input_h,
  input_stride_in_bytes,
  output_pixels,
  output_w,
  output_h,
  output_stride_in_bytes,
  pixel_layout.value,
  data_type.value,
);

@ffi.Native<
  ffi.Pointer<ffi.UnsignedChar> Function(
    ffi.Pointer<ffi.UnsignedChar>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Pointer<ffi.UnsignedChar>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.UnsignedInt,
  )
>(symbol: 'stbir_resize_uint8_linear')
external ffi.Pointer<ffi.UnsignedChar> _stbir_resize_uint8_linear(
  ffi.Pointer<ffi.UnsignedChar> input_pixels,
  int input_w,
  int input_h,
  int input_stride_in_bytes,
  ffi.Pointer<ffi.UnsignedChar> output_pixels,
  int output_w,
  int output_h,
  int output_stride_in_bytes,
  int pixel_type,
);

ffi.Pointer<ffi.UnsignedChar> stbir_resize_uint8_linear(
  ffi.Pointer<ffi.UnsignedChar> input_pixels,
  int input_w,
  int input_h,
  int input_stride_in_bytes,
  ffi.Pointer<ffi.UnsignedChar> output_pixels,
  int output_w,
  int output_h,
  int output_stride_in_bytes,
  StbirPixelLayout pixel_type,
) => _stbir_resize_uint8_linear(
  input_pixels,
  input_w,
  input_h,
  input_stride_in_bytes,
  output_pixels,
  output_w,
  output_h,
  output_stride_in_bytes,
  pixel_type.value,
);

/// ===============================================================
/// Simple-complexity API
///
/// If output_pixels is NULL (0), then we will allocate the buffer and return it to you.
/// --------------------------------
@ffi.Native<
  ffi.Pointer<ffi.UnsignedChar> Function(
    ffi.Pointer<ffi.UnsignedChar>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Pointer<ffi.UnsignedChar>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.UnsignedInt,
  )
>(symbol: 'stbir_resize_uint8_srgb')
external ffi.Pointer<ffi.UnsignedChar> _stbir_resize_uint8_srgb(
  ffi.Pointer<ffi.UnsignedChar> input_pixels,
  int input_w,
  int input_h,
  int input_stride_in_bytes,
  ffi.Pointer<ffi.UnsignedChar> output_pixels,
  int output_w,
  int output_h,
  int output_stride_in_bytes,
  int pixel_type,
);

ffi.Pointer<ffi.UnsignedChar> stbir_resize_uint8_srgb(
  ffi.Pointer<ffi.UnsignedChar> input_pixels,
  int input_w,
  int input_h,
  int input_stride_in_bytes,
  ffi.Pointer<ffi.UnsignedChar> output_pixels,
  int output_w,
  int output_h,
  int output_stride_in_bytes,
  StbirPixelLayout pixel_type,
) => _stbir_resize_uint8_srgb(
  input_pixels,
  input_w,
  input_h,
  input_stride_in_bytes,
  output_pixels,
  output_w,
  output_h,
  output_stride_in_bytes,
  pixel_type.value,
);

@ffi.Native<
  ffi.Void Function(ffi.Pointer<STBIR_RESIZE>, ffi.Pointer<ffi.Void>, ffi.Int, ffi.Pointer<ffi.Void>, ffi.Int)
>()
external void stbir_set_buffer_ptrs(
  ffi.Pointer<STBIR_RESIZE> resize,
  ffi.Pointer<ffi.Void> input_pixels,
  int input_stride_in_bytes,
  ffi.Pointer<ffi.Void> output_pixels,
  int output_stride_in_bytes,
);

/// ===============================================================
/// You can update these parameters any time after resize_init and there is no cost
/// --------------------------------
@ffi.Native<ffi.Void Function(ffi.Pointer<STBIR_RESIZE>, ffi.UnsignedInt, ffi.UnsignedInt)>(
  symbol: 'stbir_set_datatypes',
)
external void _stbir_set_datatypes(
  ffi.Pointer<STBIR_RESIZE> resize,
  int input_type,
  int output_type,
);

void stbir_set_datatypes(
  ffi.Pointer<STBIR_RESIZE> resize,
  StbirDataType input_type,
  StbirDataType output_type,
) => _stbir_set_datatypes(
  resize,
  input_type.value,
  output_type.value,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<STBIR_RESIZE>, ffi.UnsignedInt, ffi.UnsignedInt)>(
  symbol: 'stbir_set_edgemodes',
)
external int _stbir_set_edgemodes(
  ffi.Pointer<STBIR_RESIZE> resize,
  int horizontal_edge,
  int vertical_edge,
);

int stbir_set_edgemodes(
  ffi.Pointer<STBIR_RESIZE> resize,
  StbirEdge horizontal_edge,
  StbirEdge vertical_edge,
) => _stbir_set_edgemodes(
  resize,
  horizontal_edge.value,
  vertical_edge.value,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<STBIR_RESIZE>,
    ffi.Pointer<stbir__kernel_callback>,
    ffi.Pointer<stbir__support_callback>,
    ffi.Pointer<stbir__kernel_callback>,
    ffi.Pointer<stbir__support_callback>,
  )
>()
external int stbir_set_filter_callbacks(
  ffi.Pointer<STBIR_RESIZE> resize,
  ffi.Pointer<stbir__kernel_callback> horizontal_filter,
  ffi.Pointer<stbir__support_callback> horizontal_support,
  ffi.Pointer<stbir__kernel_callback> vertical_filter,
  ffi.Pointer<stbir__support_callback> vertical_support,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<STBIR_RESIZE>, ffi.UnsignedInt, ffi.UnsignedInt)>(
  symbol: 'stbir_set_filters',
)
external int _stbir_set_filters(
  ffi.Pointer<STBIR_RESIZE> resize,
  int horizontal_filter,
  int vertical_filter,
);

int stbir_set_filters(
  ffi.Pointer<STBIR_RESIZE> resize,
  StbirFilter horizontal_filter,
  StbirFilter vertical_filter,
) => _stbir_set_filters(
  resize,
  horizontal_filter.value,
  vertical_filter.value,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<STBIR_RESIZE>, ffi.Double, ffi.Double, ffi.Double, ffi.Double)>()
external int stbir_set_input_subrect(
  ffi.Pointer<STBIR_RESIZE> resize,
  double s0,
  double t0,
  double s1,
  double t1,
);

/// when inputting AND outputting non-premultiplied alpha pixels, we use a slower but higher quality technique
/// that fills the zero alpha pixel's RGB values with something plausible.  If you don't care about areas of
/// zero alpha, you can call this function to get about a 25% speed improvement for STBIR_RGBA to STBIR_RGBA
/// types of resizes.
@ffi.Native<ffi.Int Function(ffi.Pointer<STBIR_RESIZE>, ffi.Int)>()
external int stbir_set_non_pm_alpha_speed_over_quality(
  ffi.Pointer<STBIR_RESIZE> resize,
  int non_pma_alpha_speed_over_quality,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<STBIR_RESIZE>, ffi.Int, ffi.Int, ffi.Int, ffi.Int)>()
external int stbir_set_output_pixel_subrect(
  ffi.Pointer<STBIR_RESIZE> resize,
  int subx,
  int suby,
  int subw,
  int subh,
);

@ffi.Native<
  ffi.Void Function(
    ffi.Pointer<STBIR_RESIZE>,
    ffi.Pointer<stbir_input_callback>,
    ffi.Pointer<stbir_output_callback>,
  )
>()
external void stbir_set_pixel_callbacks(
  ffi.Pointer<STBIR_RESIZE> resize,
  ffi.Pointer<stbir_input_callback> input_cb,
  ffi.Pointer<stbir_output_callback> output_cb,
);

/// ===============================================================
/// If you call any of these functions, you will trigger a sampler rebuild!
/// --------------------------------
@ffi.Native<ffi.Int Function(ffi.Pointer<STBIR_RESIZE>, ffi.UnsignedInt, ffi.UnsignedInt)>(
  symbol: 'stbir_set_pixel_layouts',
)
external int _stbir_set_pixel_layouts(
  ffi.Pointer<STBIR_RESIZE> resize,
  int input_pixel_layout,
  int output_pixel_layout,
);

int stbir_set_pixel_layouts(
  ffi.Pointer<STBIR_RESIZE> resize,
  StbirPixelLayout input_pixel_layout,
  StbirPixelLayout output_pixel_layout,
) => _stbir_set_pixel_layouts(
  resize,
  input_pixel_layout.value,
  output_pixel_layout.value,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<STBIR_RESIZE>, ffi.Int, ffi.Int, ffi.Int, ffi.Int)>()
external int stbir_set_pixel_subrect(
  ffi.Pointer<STBIR_RESIZE> resize,
  int subx,
  int suby,
  int subw,
  int subh,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<STBIR_RESIZE>, ffi.Pointer<ffi.Void>)>()
external void stbir_set_user_data(
  ffi.Pointer<STBIR_RESIZE> resize,
  ffi.Pointer<ffi.Void> user_data,
);

@ffi.Native<ffi.Void Function(VecF16)>()
external void std_VecF16_clear(
  VecF16 self$1,
);

@ffi.Native<VecF16 Function(VecF16)>()
external VecF16 std_VecF16_clone(
  VecF16 self$1,
);

@ffi.Native<ffi.Pointer<ffi.Uint16> Function(VecF16)>()
external ffi.Pointer<ffi.Uint16> std_VecF16_data(
  VecF16 self$1,
);

@ffi.Native<ffi.Void Function(VecF16, VecF16)>()
external void std_VecF16_extend(
  VecF16 self$1,
  VecF16 other,
);

@ffi.Native<ffi.Void Function(VecF16)>()
external void std_VecF16_free(
  VecF16 self$1,
);

@ffi.Native<ffi.Uint16 Function(VecF16, ffi.Size)>()
external int std_VecF16_get(
  VecF16 self$1,
  int index,
);

@ffi.Native<ffi.Size Function(VecF16)>()
external int std_VecF16_length(
  VecF16 self$1,
);

@ffi.Native<VecF16 Function(ffi.Size)>()
external VecF16 std_VecF16_new(
  int length,
);

@ffi.Native<VecF16 Function(ffi.Size, ffi.Uint16)>()
external VecF16 std_VecF16_new_1(
  int length,
  int val,
);

@ffi.Native<VecF16 Function(ffi.Size, ffi.Pointer<ffi.Uint16>)>()
external VecF16 std_VecF16_new_2(
  int length,
  ffi.Pointer<ffi.Uint16> val_ptr,
);

@ffi.Native<ffi.Void Function(VecF16, ffi.Uint16)>()
external void std_VecF16_push_back(
  VecF16 self$1,
  int val,
);

@ffi.Native<ffi.Void Function(VecF16, ffi.Size)>()
external void std_VecF16_reserve(
  VecF16 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecF16, ffi.Size)>()
external void std_VecF16_resize(
  VecF16 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecF16, ffi.Size, ffi.Uint16)>()
external void std_VecF16_set(
  VecF16 self$1,
  int index,
  int val,
);

@ffi.Native<ffi.Void Function(VecF16)>()
external void std_VecF16_shrink_to_fit(
  VecF16 self$1,
);

@ffi.Native<ffi.Void Function(VecF32)>()
external void std_VecF32_clear(
  VecF32 self$1,
);

@ffi.Native<VecF32 Function(VecF32)>()
external VecF32 std_VecF32_clone(
  VecF32 self$1,
);

@ffi.Native<ffi.Pointer<float_t> Function(VecF32)>()
external ffi.Pointer<float_t> std_VecF32_data(
  VecF32 self$1,
);

@ffi.Native<ffi.Void Function(VecF32, VecF32)>()
external void std_VecF32_extend(
  VecF32 self$1,
  VecF32 other,
);

@ffi.Native<ffi.Void Function(VecF32)>()
external void std_VecF32_free(
  VecF32 self$1,
);

@ffi.Native<float_t Function(VecF32, ffi.Size)>()
external double std_VecF32_get(
  VecF32 self$1,
  int index,
);

@ffi.Native<ffi.Size Function(VecF32)>()
external int std_VecF32_length(
  VecF32 self$1,
);

@ffi.Native<VecF32 Function(ffi.Size)>()
external VecF32 std_VecF32_new(
  int length,
);

@ffi.Native<VecF32 Function(ffi.Size, float_t)>()
external VecF32 std_VecF32_new_1(
  int length,
  double val,
);

@ffi.Native<VecF32 Function(ffi.Size, ffi.Pointer<float_t>)>()
external VecF32 std_VecF32_new_2(
  int length,
  ffi.Pointer<float_t> val_ptr,
);

@ffi.Native<ffi.Void Function(VecF32, float_t)>()
external void std_VecF32_push_back(
  VecF32 self$1,
  double val,
);

@ffi.Native<ffi.Void Function(VecF32, ffi.Size)>()
external void std_VecF32_reserve(
  VecF32 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecF32, ffi.Size)>()
external void std_VecF32_resize(
  VecF32 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecF32, ffi.Size, float_t)>()
external void std_VecF32_set(
  VecF32 self$1,
  int index,
  double val,
);

@ffi.Native<ffi.Void Function(VecF32)>()
external void std_VecF32_shrink_to_fit(
  VecF32 self$1,
);

@ffi.Native<ffi.Void Function(VecF64)>()
external void std_VecF64_clear(
  VecF64 self$1,
);

@ffi.Native<VecF64 Function(VecF64)>()
external VecF64 std_VecF64_clone(
  VecF64 self$1,
);

@ffi.Native<ffi.Pointer<double_t> Function(VecF64)>()
external ffi.Pointer<double_t> std_VecF64_data(
  VecF64 self$1,
);

@ffi.Native<ffi.Void Function(VecF64, VecF64)>()
external void std_VecF64_extend(
  VecF64 self$1,
  VecF64 other,
);

@ffi.Native<ffi.Void Function(VecF64)>()
external void std_VecF64_free(
  VecF64 self$1,
);

@ffi.Native<double_t Function(VecF64, ffi.Size)>()
external double std_VecF64_get(
  VecF64 self$1,
  int index,
);

@ffi.Native<ffi.Size Function(VecF64)>()
external int std_VecF64_length(
  VecF64 self$1,
);

@ffi.Native<VecF64 Function(ffi.Size)>()
external VecF64 std_VecF64_new(
  int length,
);

@ffi.Native<VecF64 Function(ffi.Size, double_t)>()
external VecF64 std_VecF64_new_1(
  int length,
  double val,
);

@ffi.Native<VecF64 Function(ffi.Size, ffi.Pointer<double_t>)>()
external VecF64 std_VecF64_new_2(
  int length,
  ffi.Pointer<double_t> val_ptr,
);

@ffi.Native<ffi.Void Function(VecF64, double_t)>()
external void std_VecF64_push_back(
  VecF64 self$1,
  double val,
);

@ffi.Native<ffi.Void Function(VecF64, ffi.Size)>()
external void std_VecF64_reserve(
  VecF64 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecF64, ffi.Size)>()
external void std_VecF64_resize(
  VecF64 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecF64, ffi.Size, double_t)>()
external void std_VecF64_set(
  VecF64 self$1,
  int index,
  double val,
);

@ffi.Native<ffi.Void Function(VecF64)>()
external void std_VecF64_shrink_to_fit(
  VecF64 self$1,
);

@ffi.Native<ffi.Void Function(VecI16)>()
external void std_VecI16_clear(
  VecI16 self$1,
);

@ffi.Native<VecI16 Function(VecI16)>()
external VecI16 std_VecI16_clone(
  VecI16 self$1,
);

@ffi.Native<ffi.Pointer<ffi.Int16> Function(VecI16)>()
external ffi.Pointer<ffi.Int16> std_VecI16_data(
  VecI16 self$1,
);

@ffi.Native<ffi.Void Function(VecI16, VecI16)>()
external void std_VecI16_extend(
  VecI16 self$1,
  VecI16 other,
);

@ffi.Native<ffi.Void Function(VecI16)>()
external void std_VecI16_free(
  VecI16 self$1,
);

@ffi.Native<ffi.Int16 Function(VecI16, ffi.Size)>()
external int std_VecI16_get(
  VecI16 self$1,
  int index,
);

@ffi.Native<ffi.Size Function(VecI16)>()
external int std_VecI16_length(
  VecI16 self$1,
);

@ffi.Native<VecI16 Function(ffi.Size)>()
external VecI16 std_VecI16_new(
  int length,
);

@ffi.Native<VecI16 Function(ffi.Size, ffi.Int16)>()
external VecI16 std_VecI16_new_1(
  int length,
  int val,
);

@ffi.Native<VecI16 Function(ffi.Size, ffi.Pointer<ffi.Int16>)>()
external VecI16 std_VecI16_new_2(
  int length,
  ffi.Pointer<ffi.Int16> val_ptr,
);

@ffi.Native<ffi.Void Function(VecI16, ffi.Int16)>()
external void std_VecI16_push_back(
  VecI16 self$1,
  int val,
);

@ffi.Native<ffi.Void Function(VecI16, ffi.Size)>()
external void std_VecI16_reserve(
  VecI16 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecI16, ffi.Size)>()
external void std_VecI16_resize(
  VecI16 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecI16, ffi.Size, ffi.Int16)>()
external void std_VecI16_set(
  VecI16 self$1,
  int index,
  int val,
);

@ffi.Native<ffi.Void Function(VecI16)>()
external void std_VecI16_shrink_to_fit(
  VecI16 self$1,
);

@ffi.Native<ffi.Void Function(VecI32)>()
external void std_VecI32_clear(
  VecI32 self$1,
);

@ffi.Native<VecI32 Function(VecI32)>()
external VecI32 std_VecI32_clone(
  VecI32 self$1,
);

@ffi.Native<ffi.Pointer<ffi.Int32> Function(VecI32)>()
external ffi.Pointer<ffi.Int32> std_VecI32_data(
  VecI32 self$1,
);

@ffi.Native<ffi.Void Function(VecI32, VecI32)>()
external void std_VecI32_extend(
  VecI32 self$1,
  VecI32 other,
);

@ffi.Native<ffi.Void Function(VecI32)>()
external void std_VecI32_free(
  VecI32 self$1,
);

@ffi.Native<ffi.Int32 Function(VecI32, ffi.Size)>()
external int std_VecI32_get(
  VecI32 self$1,
  int index,
);

@ffi.Native<ffi.Size Function(VecI32)>()
external int std_VecI32_length(
  VecI32 self$1,
);

@ffi.Native<VecI32 Function(ffi.Size)>()
external VecI32 std_VecI32_new(
  int length,
);

@ffi.Native<VecI32 Function(ffi.Size, ffi.Int32)>()
external VecI32 std_VecI32_new_1(
  int length,
  int val,
);

@ffi.Native<VecI32 Function(ffi.Size, ffi.Pointer<ffi.Int32>)>()
external VecI32 std_VecI32_new_2(
  int length,
  ffi.Pointer<ffi.Int32> val_ptr,
);

@ffi.Native<ffi.Void Function(VecI32, ffi.Int32)>()
external void std_VecI32_push_back(
  VecI32 self$1,
  int val,
);

@ffi.Native<ffi.Void Function(VecI32, ffi.Size)>()
external void std_VecI32_reserve(
  VecI32 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecI32, ffi.Size)>()
external void std_VecI32_resize(
  VecI32 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecI32, ffi.Size, ffi.Int32)>()
external void std_VecI32_set(
  VecI32 self$1,
  int index,
  int val,
);

@ffi.Native<ffi.Void Function(VecI32)>()
external void std_VecI32_shrink_to_fit(
  VecI32 self$1,
);

@ffi.Native<ffi.Void Function(VecI64)>()
external void std_VecI64_clear(
  VecI64 self$1,
);

@ffi.Native<VecI64 Function(VecI64)>()
external VecI64 std_VecI64_clone(
  VecI64 self$1,
);

@ffi.Native<ffi.Pointer<ffi.Int64> Function(VecI64)>()
external ffi.Pointer<ffi.Int64> std_VecI64_data(
  VecI64 self$1,
);

@ffi.Native<ffi.Void Function(VecI64, VecI64)>()
external void std_VecI64_extend(
  VecI64 self$1,
  VecI64 other,
);

@ffi.Native<ffi.Void Function(VecI64)>()
external void std_VecI64_free(
  VecI64 self$1,
);

@ffi.Native<ffi.Int64 Function(VecI64, ffi.Size)>()
external int std_VecI64_get(
  VecI64 self$1,
  int index,
);

@ffi.Native<ffi.Size Function(VecI64)>()
external int std_VecI64_length(
  VecI64 self$1,
);

@ffi.Native<VecI64 Function(ffi.Size)>()
external VecI64 std_VecI64_new(
  int length,
);

@ffi.Native<VecI64 Function(ffi.Size, ffi.Int64)>()
external VecI64 std_VecI64_new_1(
  int length,
  int val,
);

@ffi.Native<VecI64 Function(ffi.Size, ffi.Pointer<ffi.Int64>)>()
external VecI64 std_VecI64_new_2(
  int length,
  ffi.Pointer<ffi.Int64> val_ptr,
);

@ffi.Native<ffi.Void Function(VecI64, ffi.Int64)>()
external void std_VecI64_push_back(
  VecI64 self$1,
  int val,
);

@ffi.Native<ffi.Void Function(VecI64, ffi.Size)>()
external void std_VecI64_reserve(
  VecI64 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecI64, ffi.Size)>()
external void std_VecI64_resize(
  VecI64 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecI64, ffi.Size, ffi.Int64)>()
external void std_VecI64_set(
  VecI64 self$1,
  int index,
  int val,
);

@ffi.Native<ffi.Void Function(VecI64)>()
external void std_VecI64_shrink_to_fit(
  VecI64 self$1,
);

@ffi.Native<ffi.Void Function(VecI8)>()
external void std_VecI8_clear(
  VecI8 self$1,
);

@ffi.Native<VecI8 Function(VecI8)>()
external VecI8 std_VecI8_clone(
  VecI8 self$1,
);

@ffi.Native<ffi.Pointer<ffi.Int8> Function(VecI8)>()
external ffi.Pointer<ffi.Int8> std_VecI8_data(
  VecI8 self$1,
);

@ffi.Native<ffi.Void Function(VecI8, VecI8)>()
external void std_VecI8_extend(
  VecI8 self$1,
  VecI8 other,
);

@ffi.Native<ffi.Void Function(VecI8)>()
external void std_VecI8_free(
  VecI8 self$1,
);

@ffi.Native<ffi.Int8 Function(VecI8, ffi.Size)>()
external int std_VecI8_get(
  VecI8 self$1,
  int index,
);

@ffi.Native<ffi.Size Function(VecI8)>()
external int std_VecI8_length(
  VecI8 self$1,
);

@ffi.Native<VecI8 Function(ffi.Size)>()
external VecI8 std_VecI8_new(
  int length,
);

@ffi.Native<VecI8 Function(ffi.Size, ffi.Int8)>()
external VecI8 std_VecI8_new_1(
  int length,
  int val,
);

@ffi.Native<VecI8 Function(ffi.Size, ffi.Pointer<ffi.Int8>)>()
external VecI8 std_VecI8_new_2(
  int length,
  ffi.Pointer<ffi.Int8> val_ptr,
);

@ffi.Native<ffi.Void Function(VecI8, ffi.Int8)>()
external void std_VecI8_push_back(
  VecI8 self$1,
  int val,
);

@ffi.Native<ffi.Void Function(VecI8, ffi.Size)>()
external void std_VecI8_reserve(
  VecI8 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecI8, ffi.Size)>()
external void std_VecI8_resize(
  VecI8 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecI8, ffi.Size, ffi.Int8)>()
external void std_VecI8_set(
  VecI8 self$1,
  int index,
  int val,
);

@ffi.Native<ffi.Void Function(VecI8)>()
external void std_VecI8_shrink_to_fit(
  VecI8 self$1,
);

@ffi.Native<ffi.Void Function(VecU16)>()
external void std_VecU16_clear(
  VecU16 self$1,
);

@ffi.Native<VecU16 Function(VecU16)>()
external VecU16 std_VecU16_clone(
  VecU16 self$1,
);

@ffi.Native<ffi.Pointer<ffi.Uint16> Function(VecU16)>()
external ffi.Pointer<ffi.Uint16> std_VecU16_data(
  VecU16 self$1,
);

@ffi.Native<ffi.Void Function(VecU16, VecU16)>()
external void std_VecU16_extend(
  VecU16 self$1,
  VecU16 other,
);

@ffi.Native<ffi.Void Function(VecU16)>()
external void std_VecU16_free(
  VecU16 self$1,
);

@ffi.Native<ffi.Uint16 Function(VecU16, ffi.Size)>()
external int std_VecU16_get(
  VecU16 self$1,
  int index,
);

@ffi.Native<ffi.Size Function(VecU16)>()
external int std_VecU16_length(
  VecU16 self$1,
);

@ffi.Native<VecU16 Function(ffi.Size)>()
external VecU16 std_VecU16_new(
  int length,
);

@ffi.Native<VecU16 Function(ffi.Size, ffi.Uint16)>()
external VecU16 std_VecU16_new_1(
  int length,
  int val,
);

@ffi.Native<VecU16 Function(ffi.Size, ffi.Pointer<ffi.Uint16>)>()
external VecU16 std_VecU16_new_2(
  int length,
  ffi.Pointer<ffi.Uint16> val_ptr,
);

@ffi.Native<ffi.Void Function(VecU16, ffi.Uint16)>()
external void std_VecU16_push_back(
  VecU16 self$1,
  int val,
);

@ffi.Native<ffi.Void Function(VecU16, ffi.Size)>()
external void std_VecU16_reserve(
  VecU16 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecU16, ffi.Size)>()
external void std_VecU16_resize(
  VecU16 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecU16, ffi.Size, ffi.Uint16)>()
external void std_VecU16_set(
  VecU16 self$1,
  int index,
  int val,
);

@ffi.Native<ffi.Void Function(VecU16)>()
external void std_VecU16_shrink_to_fit(
  VecU16 self$1,
);

@ffi.Native<ffi.Void Function(VecU32)>()
external void std_VecU32_clear(
  VecU32 self$1,
);

@ffi.Native<VecU32 Function(VecU32)>()
external VecU32 std_VecU32_clone(
  VecU32 self$1,
);

@ffi.Native<ffi.Pointer<ffi.Uint32> Function(VecU32)>()
external ffi.Pointer<ffi.Uint32> std_VecU32_data(
  VecU32 self$1,
);

@ffi.Native<ffi.Void Function(VecU32, VecU32)>()
external void std_VecU32_extend(
  VecU32 self$1,
  VecU32 other,
);

@ffi.Native<ffi.Void Function(VecU32)>()
external void std_VecU32_free(
  VecU32 self$1,
);

@ffi.Native<ffi.Uint32 Function(VecU32, ffi.Size)>()
external int std_VecU32_get(
  VecU32 self$1,
  int index,
);

@ffi.Native<ffi.Size Function(VecU32)>()
external int std_VecU32_length(
  VecU32 self$1,
);

@ffi.Native<VecU32 Function(ffi.Size)>()
external VecU32 std_VecU32_new(
  int length,
);

@ffi.Native<VecU32 Function(ffi.Size, ffi.Uint32)>()
external VecU32 std_VecU32_new_1(
  int length,
  int val,
);

@ffi.Native<VecU32 Function(ffi.Size, ffi.Pointer<ffi.Uint32>)>()
external VecU32 std_VecU32_new_2(
  int length,
  ffi.Pointer<ffi.Uint32> val_ptr,
);

@ffi.Native<ffi.Void Function(VecU32, ffi.Uint32)>()
external void std_VecU32_push_back(
  VecU32 self$1,
  int val,
);

@ffi.Native<ffi.Void Function(VecU32, ffi.Size)>()
external void std_VecU32_reserve(
  VecU32 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecU32, ffi.Size)>()
external void std_VecU32_resize(
  VecU32 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecU32, ffi.Size, ffi.Uint32)>()
external void std_VecU32_set(
  VecU32 self$1,
  int index,
  int val,
);

@ffi.Native<ffi.Void Function(VecU32)>()
external void std_VecU32_shrink_to_fit(
  VecU32 self$1,
);

@ffi.Native<ffi.Void Function(VecU64)>()
external void std_VecU64_clear(
  VecU64 self$1,
);

@ffi.Native<VecU64 Function(VecU64)>()
external VecU64 std_VecU64_clone(
  VecU64 self$1,
);

@ffi.Native<ffi.Pointer<ffi.Uint64> Function(VecU64)>()
external ffi.Pointer<ffi.Uint64> std_VecU64_data(
  VecU64 self$1,
);

@ffi.Native<ffi.Void Function(VecU64, VecU64)>()
external void std_VecU64_extend(
  VecU64 self$1,
  VecU64 other,
);

@ffi.Native<ffi.Void Function(VecU64)>()
external void std_VecU64_free(
  VecU64 self$1,
);

@ffi.Native<ffi.Uint64 Function(VecU64, ffi.Size)>()
external int std_VecU64_get(
  VecU64 self$1,
  int index,
);

@ffi.Native<ffi.Size Function(VecU64)>()
external int std_VecU64_length(
  VecU64 self$1,
);

@ffi.Native<VecU64 Function(ffi.Size)>()
external VecU64 std_VecU64_new(
  int length,
);

@ffi.Native<VecU64 Function(ffi.Size, ffi.Uint64)>()
external VecU64 std_VecU64_new_1(
  int length,
  int val,
);

@ffi.Native<VecU64 Function(ffi.Size, ffi.Pointer<ffi.Uint64>)>()
external VecU64 std_VecU64_new_2(
  int length,
  ffi.Pointer<ffi.Uint64> val_ptr,
);

@ffi.Native<ffi.Void Function(VecU64, ffi.Uint64)>()
external void std_VecU64_push_back(
  VecU64 self$1,
  int val,
);

@ffi.Native<ffi.Void Function(VecU64, ffi.Size)>()
external void std_VecU64_reserve(
  VecU64 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecU64, ffi.Size)>()
external void std_VecU64_resize(
  VecU64 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecU64, ffi.Size, ffi.Uint64)>()
external void std_VecU64_set(
  VecU64 self$1,
  int index,
  int val,
);

@ffi.Native<ffi.Void Function(VecU64)>()
external void std_VecU64_shrink_to_fit(
  VecU64 self$1,
);

@ffi.Native<ffi.Void Function(VecU8)>()
external void std_VecU8_clear(
  VecU8 self$1,
);

@ffi.Native<VecU8 Function(VecU8)>()
external VecU8 std_VecU8_clone(
  VecU8 self$1,
);

@ffi.Native<ffi.Pointer<ffi.Uint8> Function(VecU8)>()
external ffi.Pointer<ffi.Uint8> std_VecU8_data(
  VecU8 self$1,
);

@ffi.Native<ffi.Void Function(VecU8, VecU8)>()
external void std_VecU8_extend(
  VecU8 self$1,
  VecU8 other,
);

@ffi.Native<ffi.Void Function(VecU8)>()
external void std_VecU8_free(
  VecU8 self$1,
);

@ffi.Native<ffi.Uint8 Function(VecU8, ffi.Size)>()
external int std_VecU8_get(
  VecU8 self$1,
  int index,
);

@ffi.Native<ffi.Size Function(VecU8)>()
external int std_VecU8_length(
  VecU8 self$1,
);

@ffi.Native<VecU8 Function(ffi.Size)>()
external VecU8 std_VecU8_new(
  int length,
);

@ffi.Native<VecU8 Function(ffi.Size, ffi.Uint8)>()
external VecU8 std_VecU8_new_1(
  int length,
  int val,
);

@ffi.Native<VecU8 Function(ffi.Size, ffi.Pointer<ffi.Uint8>)>()
external VecU8 std_VecU8_new_2(
  int length,
  ffi.Pointer<ffi.Uint8> val_ptr,
);

@ffi.Native<ffi.Void Function(VecU8, ffi.Uint8)>()
external void std_VecU8_push_back(
  VecU8 self$1,
  int val,
);

@ffi.Native<ffi.Void Function(VecU8, ffi.Size)>()
external void std_VecU8_reserve(
  VecU8 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecU8, ffi.Size)>()
external void std_VecU8_resize(
  VecU8 self$1,
  int new_len,
);

@ffi.Native<ffi.Void Function(VecU8, ffi.Size, ffi.Uint8)>()
external void std_VecU8_set(
  VecU8 self$1,
  int index,
  int val,
);

@ffi.Native<ffi.Void Function(VecU8)>()
external void std_VecU8_shrink_to_fit(
  VecU8 self$1,
);

const addresses = _SymbolAddresses();

class _SymbolAddresses {
  const _SymbolAddresses();
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(mnn_auto_time_t)>> get mnn_auto_time_destroy =>
      ffi.Native.addressOf(self.mnn_auto_time_destroy);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(mnn_cv_image_process_t)>>
  get mnn_cv_image_process_destroy => ffi.Native.addressOf(self.mnn_cv_image_process_destroy);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(mnn_cv_matrix_t)>> get mnn_cv_matrix_destroy =>
      ffi.Native.addressOf(self.mnn_cv_matrix_destroy);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(EXPRP_t)>> get mnn_expr_Expr_free =>
      ffi.Native.addressOf(self.mnn_expr_Expr_free);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>> get mnn_expr_VARMAP_free =>
      ffi.Native.addressOf(self.mnn_expr_VARMAP_free);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>> get mnn_expr_VARP_free =>
      ffi.Native.addressOf(self.mnn_expr_VARP_free);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>> get mnn_expr_Variable_Info_free =>
      ffi.Native.addressOf(self.mnn_expr_Variable_Info_free);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>> get mnn_expr_VecVARP_free =>
      ffi.Native.addressOf(self.mnn_expr_VecVARP_free);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>> get mnn_expr_VecWeakEXPRP_free =>
      ffi.Native.addressOf(self.mnn_expr_VecWeakEXPRP_free);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(mnn_interpreter_t)>> get mnn_interpreter_destroy =>
      ffi.Native.addressOf(self.mnn_interpreter_destroy);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(mnn_module_t)>> get mnn_module_destroy =>
      ffi.Native.addressOf(self.mnn_module_destroy);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(mnn_module_info_t)>> get mnn_module_info_destroy =>
      ffi.Native.addressOf(self.mnn_module_info_destroy);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(mnn_runtime_info_t)>> get mnn_runtime_info_destroy =>
      ffi.Native.addressOf(self.mnn_runtime_info_destroy);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(mnn_runtime_manager_t)>> get mnn_runtime_manager_destroy =>
      ffi.Native.addressOf(self.mnn_runtime_manager_destroy);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(mnn_tensor_t)>> get mnn_tensor_destroy =>
      ffi.Native.addressOf(self.mnn_tensor_destroy);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(mnn_timer_t)>> get mnn_timer_destroy =>
      ffi.Native.addressOf(self.mnn_timer_destroy);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>> get stbi_image_free =>
      ffi.Native.addressOf(self.stbi_image_free);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<STBIR_RESIZE>)>> get stbir_free_samplers =>
      ffi.Native.addressOf(self.stbir_free_samplers);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(VecF16)>> get std_VecF16_free =>
      ffi.Native.addressOf(self.std_VecF16_free);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(VecF32)>> get std_VecF32_free =>
      ffi.Native.addressOf(self.std_VecF32_free);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(VecF64)>> get std_VecF64_free =>
      ffi.Native.addressOf(self.std_VecF64_free);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(VecI16)>> get std_VecI16_free =>
      ffi.Native.addressOf(self.std_VecI16_free);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(VecI32)>> get std_VecI32_free =>
      ffi.Native.addressOf(self.std_VecI32_free);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(VecI64)>> get std_VecI64_free =>
      ffi.Native.addressOf(self.std_VecI64_free);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(VecI8)>> get std_VecI8_free =>
      ffi.Native.addressOf(self.std_VecI8_free);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(VecU16)>> get std_VecU16_free =>
      ffi.Native.addressOf(self.std_VecU16_free);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(VecU32)>> get std_VecU32_free =>
      ffi.Native.addressOf(self.std_VecU32_free);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(VecU64)>> get std_VecU64_free =>
      ffi.Native.addressOf(self.std_VecU64_free);
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(VecU8)>> get std_VecU8_free =>
      ffi.Native.addressOf(self.std_VecU8_free);
}

enum DimensionType {
  MNN_TENSORFLOW(0),
  MNN_CAFFE(1),
  MNN_CAFFE_C4(2)
  ;

  final int value;
  const DimensionType(this.value);

  static DimensionType fromValue(int value) => switch (value) {
    0 => MNN_TENSORFLOW,
    1 => MNN_CAFFE,
    2 => MNN_CAFFE_C4,
    _ => throw ArgumentError('Unknown value for DimensionType: $value'),
  };
}

typedef EXPRP_t = ffi.Pointer<ffi.Void>;

/// Error code enum
enum ErrorCode {
  MNNC_NO_ERROR(0),
  MNNC_OUT_OF_MEMORY(1),
  MNNC_NOT_SUPPORT(2),
  MNNC_COMPUTE_SIZE_ERROR(3),
  MNNC_NO_EXECUTION(4),
  MNNC_INVALID_VALUE(5),

  /// User error
  MNNC_INPUT_DATA_ERROR(10),
  MNNC_CALL_BACK_STOP(11),

  /// Op Resize Error
  MNNC_TENSOR_NOT_SUPPORT(20),
  MNNC_TENSOR_NEED_DIVIDE(21),

  /// File error
  MNNC_FILE_CREATE_FAILED(30),
  MNNC_FILE_REMOVE_FAILED(31),
  MNNC_FILE_OPEN_FAILED(32),
  MNNC_FILE_CLOSE_FAILED(33),
  MNNC_FILE_RESIZE_FAILED(34),
  MNNC_FILE_SEEK_FAILED(35),
  MNNC_FILE_NOT_EXIST(36),
  MNNC_FILE_UNMAP_FAILED(37),

  /// custom
  MNNC_BOOL_TRUE(100),
  MNNC_BOOL_FALSE(101),
  MNNC_UNKNOWN_ERROR(102),
  MNNC_INVALID_PTR(103)
  ;

  final int value;
  const ErrorCode(this.value);

  static ErrorCode fromValue(int value) => switch (value) {
    0 => MNNC_NO_ERROR,
    1 => MNNC_OUT_OF_MEMORY,
    2 => MNNC_NOT_SUPPORT,
    3 => MNNC_COMPUTE_SIZE_ERROR,
    4 => MNNC_NO_EXECUTION,
    5 => MNNC_INVALID_VALUE,
    10 => MNNC_INPUT_DATA_ERROR,
    11 => MNNC_CALL_BACK_STOP,
    20 => MNNC_TENSOR_NOT_SUPPORT,
    21 => MNNC_TENSOR_NEED_DIVIDE,
    30 => MNNC_FILE_CREATE_FAILED,
    31 => MNNC_FILE_REMOVE_FAILED,
    32 => MNNC_FILE_OPEN_FAILED,
    33 => MNNC_FILE_CLOSE_FAILED,
    34 => MNNC_FILE_RESIZE_FAILED,
    35 => MNNC_FILE_SEEK_FAILED,
    36 => MNNC_FILE_NOT_EXIST,
    37 => MNNC_FILE_UNMAP_FAILED,
    100 => MNNC_BOOL_TRUE,
    101 => MNNC_BOOL_FALSE,
    102 => MNNC_UNKNOWN_ERROR,
    103 => MNNC_INVALID_PTR,
    _ => throw ArgumentError('Unknown value for ErrorCode: $value'),
  };
}

typedef FILE = _iobuf;

/// Types in the halide type system. They can be ints, unsigned ints,
/// or floats (of various bit-widths), or a handle (which is always 64-bits).
/// Note that the int/uint/float values do not imply a specific bit width
/// (the bit width is expected to be encoded in a separate value).
enum HalideTypeCode {
  /// !< signed integers
  halide_type_int(0),

  /// !< unsigned integers
  halide_type_uint(1),

  /// !< IEEE floating point numbers
  halide_type_float(2),

  /// !< opaque pointer type (void *)
  halide_type_handle(3),

  /// !< floating point numbers in the bfloat format
  halide_type_bfloat(4)
  ;

  final int value;
  const HalideTypeCode(this.value);

  static HalideTypeCode fromValue(int value) => switch (value) {
    0 => halide_type_int,
    1 => halide_type_uint,
    2 => halide_type_float,
    3 => halide_type_handle,
    4 => halide_type_bfloat,
    _ => throw ArgumentError('Unknown value for HalideTypeCode: $value'),
  };
}

enum HandleDataType {
  MNN_HANDLE_NONE(0),
  MNN_HANDLE_STRING(1)
  ;

  final int value;
  const HandleDataType(this.value);

  static HandleDataType fromValue(int value) => switch (value) {
    0 => MNN_HANDLE_NONE,
    1 => MNN_HANDLE_STRING,
    _ => throw ArgumentError('Unknown value for HandleDataType: $value'),
  };
}

enum MapType {
  MNN_MAP_TENSOR_WRITE(0),
  MNN_MAP_TENSOR_READ(1)
  ;

  final int value;
  const MapType(this.value);

  static MapType fromValue(int value) => switch (value) {
    0 => MNN_MAP_TENSOR_WRITE,
    1 => MNN_MAP_TENSOR_READ,
    _ => throw ArgumentError('Unknown value for MapType: $value'),
  };
}

typedef Net_t = ffi.Pointer<ffi.Void>;
typedef OpT_t = ffi.Pointer<ffi.Void>;
typedef Op_t = ffi.Pointer<ffi.Void>;

final class STBIR_RESIZE extends ffi.Struct {
  external ffi.Pointer<ffi.Void> user_data;

  external ffi.Pointer<ffi.Void> input_pixels;

  @ffi.Int()
  external int input_w;

  @ffi.Int()
  external int input_h;

  @ffi.Double()
  external double input_s0;

  @ffi.Double()
  external double input_t0;

  @ffi.Double()
  external double input_s1;

  @ffi.Double()
  external double input_t1;

  external ffi.Pointer<stbir_input_callback> input_cb;

  external ffi.Pointer<ffi.Void> output_pixels;

  @ffi.Int()
  external int output_w;

  @ffi.Int()
  external int output_h;

  @ffi.Int()
  external int output_subx;

  @ffi.Int()
  external int output_suby;

  @ffi.Int()
  external int output_subw;

  @ffi.Int()
  external int output_subh;

  external ffi.Pointer<stbir_output_callback> output_cb;

  @ffi.Int()
  external int input_stride_in_bytes;

  @ffi.Int()
  external int output_stride_in_bytes;

  @ffi.Int()
  external int splits;

  @ffi.Int()
  external int fast_alpha;

  @ffi.Int()
  external int needs_rebuild;

  @ffi.Int()
  external int called_alloc;

  @ffi.UnsignedInt()
  external int input_pixel_layout_publicAsInt;

  StbirPixelLayout get input_pixel_layout_public =>
      StbirPixelLayout.fromValue(input_pixel_layout_publicAsInt);

  @ffi.UnsignedInt()
  external int output_pixel_layout_publicAsInt;

  StbirPixelLayout get output_pixel_layout_public =>
      StbirPixelLayout.fromValue(output_pixel_layout_publicAsInt);

  @ffi.UnsignedInt()
  external int input_data_typeAsInt;

  StbirDataType get input_data_type => StbirDataType.fromValue(input_data_typeAsInt);

  @ffi.UnsignedInt()
  external int output_data_typeAsInt;

  StbirDataType get output_data_type => StbirDataType.fromValue(output_data_typeAsInt);

  @ffi.UnsignedInt()
  external int horizontal_filterAsInt;

  StbirFilter get horizontal_filter => StbirFilter.fromValue(horizontal_filterAsInt);

  @ffi.UnsignedInt()
  external int vertical_filterAsInt;

  StbirFilter get vertical_filter => StbirFilter.fromValue(vertical_filterAsInt);

  @ffi.UnsignedInt()
  external int horizontal_edgeAsInt;

  StbirEdge get horizontal_edge => StbirEdge.fromValue(horizontal_edgeAsInt);

  @ffi.UnsignedInt()
  external int vertical_edgeAsInt;

  StbirEdge get vertical_edge => StbirEdge.fromValue(vertical_edgeAsInt);

  external ffi.Pointer<stbir__kernel_callback> horizontal_filter_kernel;

  external ffi.Pointer<stbir__support_callback> horizontal_filter_support;

  external ffi.Pointer<stbir__kernel_callback> vertical_filter_kernel;

  external ffi.Pointer<stbir__support_callback> vertical_filter_support;

  external ffi.Pointer<stbir__info> samplers;
}

const int STBI_VERSION = 1;

const int STBI_default = 0;

const int STBI_grey = 1;

const int STBI_grey_alpha = 2;

const int STBI_rgb = 3;

const int STBI_rgb_alpha = 4;

enum StbirDataType {
  STBIR_TYPE_UINT8(0),
  STBIR_TYPE_UINT8_SRGB(1),

  /// alpha channel, when present, should also be SRGB (this is very unusual)
  STBIR_TYPE_UINT8_SRGB_ALPHA(2),
  STBIR_TYPE_UINT16(3),
  STBIR_TYPE_FLOAT(4),
  STBIR_TYPE_HALF_FLOAT(5)
  ;

  final int value;
  const StbirDataType(this.value);

  static StbirDataType fromValue(int value) => switch (value) {
    0 => STBIR_TYPE_UINT8,
    1 => STBIR_TYPE_UINT8_SRGB,
    2 => STBIR_TYPE_UINT8_SRGB_ALPHA,
    3 => STBIR_TYPE_UINT16,
    4 => STBIR_TYPE_FLOAT,
    5 => STBIR_TYPE_HALF_FLOAT,
    _ => throw ArgumentError('Unknown value for StbirDataType: $value'),
  };
}

/// ===============================================================
/// Medium-complexity API
///
/// This extends the easy-to-use API as follows:
///
/// * Can specify the datatype - U8, U8_SRGB, U16, FLOAT, HALF_FLOAT
/// * Edge wrap can selected explicitly
/// * Filter can be selected explicitly
/// --------------------------------
enum StbirEdge {
  STBIR_EDGE_CLAMP(0),
  STBIR_EDGE_REFLECT(1),

  /// this edge mode is slower and uses more memory
  STBIR_EDGE_WRAP(2),
  STBIR_EDGE_ZERO(3)
  ;

  final int value;
  const StbirEdge(this.value);

  static StbirEdge fromValue(int value) => switch (value) {
    0 => STBIR_EDGE_CLAMP,
    1 => STBIR_EDGE_REFLECT,
    2 => STBIR_EDGE_WRAP,
    3 => STBIR_EDGE_ZERO,
    _ => throw ArgumentError('Unknown value for StbirEdge: $value'),
  };
}

enum StbirFilter {
  /// use same filter type that easy-to-use API chooses
  STBIR_FILTER_DEFAULT(0),

  /// A trapezoid w/1-pixel wide ramps, same result as box for integer scale ratios
  STBIR_FILTER_BOX(1),

  /// On upsampling, produces same results as bilinear texture filtering
  STBIR_FILTER_TRIANGLE(2),

  /// The cubic b-spline (aka Mitchell-Netrevalli with B=1,C=0), gaussian-esque
  STBIR_FILTER_CUBICBSPLINE(3),

  /// An interpolating cubic spline
  STBIR_FILTER_CATMULLROM(4),

  /// Mitchell-Netrevalli filter with B=1/3, C=1/3
  STBIR_FILTER_MITCHELL(5),

  /// Simple point sampling
  STBIR_FILTER_POINT_SAMPLE(6),

  /// User callback specified
  STBIR_FILTER_OTHER(7)
  ;

  final int value;
  const StbirFilter(this.value);

  static StbirFilter fromValue(int value) => switch (value) {
    0 => STBIR_FILTER_DEFAULT,
    1 => STBIR_FILTER_BOX,
    2 => STBIR_FILTER_TRIANGLE,
    3 => STBIR_FILTER_CUBICBSPLINE,
    4 => STBIR_FILTER_CATMULLROM,
    5 => STBIR_FILTER_MITCHELL,
    6 => STBIR_FILTER_POINT_SAMPLE,
    7 => STBIR_FILTER_OTHER,
    _ => throw ArgumentError('Unknown value for StbirFilter: $value'),
  };
}

/// stbir_pixel_layout specifies:
/// number of channels
/// order of channels
/// whether color is premultiplied by alpha
/// for back compatibility, you can cast the old channel count to an stbir_pixel_layout
enum StbirPixelLayout {
  STBIR_1CHANNEL(1),
  STBIR_2CHANNEL(2),

  /// 3-chan, with order specified (for channel flipping)
  STBIR_RGB(3),

  /// 3-chan, with order specified (for channel flipping)
  STBIR_BGR(0),
  STBIR_4CHANNEL(5),

  /// alpha formats, where alpha is NOT premultiplied into color channels
  STBIR_RGBA(4),
  STBIR_BGRA(6),
  STBIR_ARGB(7),
  STBIR_ABGR(8),
  STBIR_RA(9),
  STBIR_AR(10),

  /// alpha formats, where alpha is premultiplied into color channels
  STBIR_RGBA_PM(11),
  STBIR_BGRA_PM(12),
  STBIR_ARGB_PM(13),
  STBIR_ABGR_PM(14),
  STBIR_RA_PM(15),
  STBIR_AR_PM(16)
  ;

  /// alpha formats, where NO alpha weighting is applied at all!
  static const STBIR_RGBA_NO_AW = STBIR_RGBA_PM;

  /// these are just synonyms for the _PM flags (which also do
  static const STBIR_BGRA_NO_AW = STBIR_BGRA_PM;

  /// no alpha weighting). These names just make it more clear
  static const STBIR_ARGB_NO_AW = STBIR_ARGB_PM;

  /// for some folks).
  static const STBIR_ABGR_NO_AW = STBIR_ABGR_PM;
  static const STBIR_RA_NO_AW = STBIR_RA_PM;
  static const STBIR_AR_NO_AW = STBIR_AR_PM;

  final int value;
  const StbirPixelLayout(this.value);

  static StbirPixelLayout fromValue(int value) => switch (value) {
    1 => STBIR_1CHANNEL,
    2 => STBIR_2CHANNEL,
    3 => STBIR_RGB,
    0 => STBIR_BGR,
    5 => STBIR_4CHANNEL,
    4 => STBIR_RGBA,
    6 => STBIR_BGRA,
    7 => STBIR_ARGB,
    8 => STBIR_ABGR,
    9 => STBIR_RA,
    10 => STBIR_AR,
    11 => STBIR_RGBA_PM,
    12 => STBIR_BGRA_PM,
    13 => STBIR_ARGB_PM,
    14 => STBIR_ABGR_PM,
    15 => STBIR_RA_PM,
    16 => STBIR_AR_PM,
    _ => throw ArgumentError('Unknown value for StbirPixelLayout: $value'),
  };

  @override
  String toString() {
    if (this == STBIR_RGBA_PM) return "StbirPixelLayout.STBIR_RGBA_PM, StbirPixelLayout.STBIR_RGBA_NO_AW";
    if (this == STBIR_BGRA_PM) return "StbirPixelLayout.STBIR_BGRA_PM, StbirPixelLayout.STBIR_BGRA_NO_AW";
    if (this == STBIR_ARGB_PM) return "StbirPixelLayout.STBIR_ARGB_PM, StbirPixelLayout.STBIR_ARGB_NO_AW";
    if (this == STBIR_ABGR_PM) return "StbirPixelLayout.STBIR_ABGR_PM, StbirPixelLayout.STBIR_ABGR_NO_AW";
    if (this == STBIR_RA_PM) return "StbirPixelLayout.STBIR_RA_PM, StbirPixelLayout.STBIR_RA_NO_AW";
    if (this == STBIR_AR_PM) return "StbirPixelLayout.STBIR_AR_PM, StbirPixelLayout.STBIR_AR_NO_AW";
    return super.toString();
  }
}

/// CPU:number of threads in parallel , Or GPU: mode setting
final class UnnamedUnion extends ffi.Union {
  @ffi.Int()
  external int num_thread;

  @ffi.Int()
  external int mode;
}

final class UnnamedUnion$1 extends ffi.Union {
  external ffi.Pointer<ffi.Void> sharedContext;

  @ffi.Size()
  external int flags;
}

typedef VARMAP_PAIR_t = ffi.Pointer<ffi.Void>;
typedef VARMAP_t = ffi.Pointer<ffi.Void>;
typedef VARP_t = ffi.Pointer<ffi.Void>;

final class Variable_expr_pair extends ffi.Struct {
  external EXPRP_t expr;

  @ffi.Int()
  external int index;
}

typedef VecChar = ffi.Pointer<ffi.Void>;
typedef VecF16 = ffi.Pointer<ffi.Void>;
typedef VecF32 = ffi.Pointer<ffi.Void>;
typedef VecF64 = ffi.Pointer<ffi.Void>;
typedef VecI16 = ffi.Pointer<ffi.Void>;
typedef VecI32 = ffi.Pointer<ffi.Void>;
typedef VecI64 = ffi.Pointer<ffi.Void>;
typedef VecI8 = ffi.Pointer<ffi.Void>;
typedef VecU16 = ffi.Pointer<ffi.Void>;
typedef VecU32 = ffi.Pointer<ffi.Void>;
typedef VecU64 = ffi.Pointer<ffi.Void>;
typedef VecU8 = ffi.Pointer<ffi.Void>;
typedef VecUChar = ffi.Pointer<ffi.Void>;
typedef VecVARP_t = ffi.Pointer<ffi.Void>;
typedef VecWeakEXPRP_t = ffi.Pointer<ffi.Void>;

final class _iobuf extends ffi.Struct {
  external ffi.Pointer<ffi.Void> _Placeholder;
}

typedef double_t = ffi.Double;
typedef Dartdouble_t = double;
typedef float_t = ffi.Float;
typedef Dartfloat_t = double;

/// The raw representation of an image passed around by generated
/// Halide code. It includes some stuff to track whether the image is
/// not actually in main memory, but instead on a device (like a
/// GPU). For a more convenient C++ wrapper, use Halide::Buffer<T>.
final class halide_buffer_c_t extends ffi.Struct {
  /// A device-handle for e.g. GPU memory used to back this buffer.
  @ffi.Uint64()
  external int device;

  /// The interface used to interpret the above handle.
  external ffi.Pointer<halide_device_interface_t> device_interface;

  /// A pointer to the start of the data in main memory. In terms of
  /// the Halide coordinate system, this is the address of the min
  /// coordinates (defined below).
  external ffi.Pointer<ffi.Uint8> host;

  /// flags with various meanings.
  @ffi.Uint64()
  external int flags;

  /// The type of each buffer element.
  external halide_type_c_t type;

  /// The dimensionality of the buffer.
  @ffi.Int32()
  external int dimensions;

  /// The shape of the buffer. Halide does not own this array - you
  /// must manage the memory for it yourself.
  external ffi.Pointer<halide_dimension_t> dim;

  /// Pads the buffer up to a multiple of 8 bytes
  external ffi.Pointer<ffi.Void> padding;
}

enum halide_buffer_flags {
  halide_buffer_flag_host_dirty(1),
  halide_buffer_flag_device_dirty(2)
  ;

  final int value;
  const halide_buffer_flags(this.value);

  static halide_buffer_flags fromValue(int value) => switch (value) {
    1 => halide_buffer_flag_host_dirty,
    2 => halide_buffer_flag_device_dirty,
    _ => throw ArgumentError('Unknown value for halide_buffer_flags: $value'),
  };
}

/// The raw representation of an image passed around by generated
/// Halide code. It includes some stuff to track whether the image is
/// not actually in main memory, but instead on a device (like a
/// GPU). For a more convenient C++ wrapper, use Halide::Buffer<T>.
final class halide_buffer_t extends ffi.Struct {
  /// A device-handle for e.g. GPU memory used to back this buffer.
  @ffi.Uint64()
  external int device;

  /// The interface used to interpret the above handle.
  external ffi.Pointer<halide_device_interface_t> device_interface;

  /// A pointer to the start of the data in main memory. In terms of
  /// the Halide coordinate system, this is the address of the min
  /// coordinates (defined below).
  external ffi.Pointer<ffi.Uint8> host;

  /// flags with various meanings.
  @ffi.Uint64()
  external int flags;

  /// The type of each buffer element.
  external halide_type_t type;

  /// The dimensionality of the buffer.
  @ffi.Int32()
  external int dimensions;

  /// The shape of the buffer. Halide does not own this array - you
  /// must manage the memory for it yourself.
  external ffi.Pointer<halide_dimension_t> dim;

  /// Pads the buffer up to a multiple of 8 bytes
  external ffi.Pointer<ffi.Void> padding;
}

/// An opaque struct containing per-GPU API implementations of the
/// device functions.
final class halide_device_interface_impl_t extends ffi.Opaque {}

/// Each GPU API provides a halide_device_interface_t struct pointing
/// to the code that manages device allocations. You can access these
/// functions directly from the struct member function pointers, or by
/// calling the functions declared below. Note that the global
/// functions are not available when using Halide as a JIT compiler.
/// If you are using raw halide_buffer_t in that context you must use
/// the function pointers in the device_interface struct.
///
/// The function pointers below are currently the same for every GPU
/// API; only the impl field varies. These top-level functions do the
/// bookkeeping that is common across all GPU APIs, and then dispatch
/// to more API-specific functions via another set of function pointers
/// hidden inside the impl field.
final class halide_device_interface_t extends ffi.Struct {
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int Function(
        ffi.Pointer<ffi.Void> user_context,
        ffi.Pointer<halide_buffer_t> buf,
        ffi.Pointer<halide_device_interface_t> device_interface,
      )
    >
  >
  device_malloc;

  external ffi.Pointer<
    ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Void> user_context, ffi.Pointer<halide_buffer_t> buf)>
  >
  device_free;

  external ffi.Pointer<
    ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Void> user_context, ffi.Pointer<halide_buffer_t> buf)>
  >
  device_sync;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Void Function(
        ffi.Pointer<ffi.Void> user_context,
        ffi.Pointer<halide_device_interface_t> device_interface,
      )
    >
  >
  device_release;

  external ffi.Pointer<
    ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Void> user_context, ffi.Pointer<halide_buffer_t> buf)>
  >
  copy_to_host;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int Function(
        ffi.Pointer<ffi.Void> user_context,
        ffi.Pointer<halide_buffer_t> buf,
        ffi.Pointer<halide_device_interface_t> device_interface,
      )
    >
  >
  copy_to_device;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int Function(
        ffi.Pointer<ffi.Void> user_context,
        ffi.Pointer<halide_buffer_t> buf,
        ffi.Pointer<halide_device_interface_t> device_interface,
      )
    >
  >
  device_and_host_malloc;

  external ffi.Pointer<
    ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Void> user_context, ffi.Pointer<halide_buffer_t> buf)>
  >
  device_and_host_free;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int Function(
        ffi.Pointer<ffi.Void> user_context,
        ffi.Pointer<halide_buffer_t> src,
        ffi.Pointer<halide_device_interface_t> dst_device_interface,
        ffi.Pointer<halide_buffer_t> dst,
      )
    >
  >
  buffer_copy;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int Function(
        ffi.Pointer<ffi.Void> user_context,
        ffi.Pointer<halide_buffer_t> src,
        ffi.Pointer<halide_buffer_t> dst,
      )
    >
  >
  device_crop;

  external ffi.Pointer<
    ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Void> user_context, ffi.Pointer<halide_buffer_t> buf)>
  >
  device_release_crop;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int Function(
        ffi.Pointer<ffi.Void> user_context,
        ffi.Pointer<halide_buffer_t> buf,
        ffi.Uint64 handle,
        ffi.Pointer<halide_device_interface_t> device_interface,
      )
    >
  >
  wrap_native;

  external ffi.Pointer<
    ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Void> user_context, ffi.Pointer<halide_buffer_t> buf)>
  >
  detach_native;

  external ffi.Pointer<halide_device_interface_impl_t> impl;
}

final class halide_dimension_t extends ffi.Struct {
  @ffi.Int32()
  external int min;

  @ffi.Int32()
  external int extent;

  @ffi.Int32()
  external int stride;

  /// Per-dimension flags. None are defined yet (This is reserved for future use).
  @ffi.Uint32()
  external int flags;
}

final class halide_type_c_t extends ffi.Struct {
  @ffi.Uint8()
  external int code;

  @ffi.Uint8()
  external int bits;

  @ffi.Uint16()
  external int lanes;
}

/// A runtime tag for a type in the halide type system. Can be ints,
/// unsigned ints, or floats of various bit-widths (the 'bits'
/// field). Can also be vectors of the same (by setting the 'lanes'
/// field to something larger than one). This struct should be
/// exactly 32-bits in size.
final class halide_type_t extends ffi.Struct {
  /// halide_type_code_t
  @ffi.UnsignedInt()
  external int codeAsInt;

  HalideTypeCode get code => HalideTypeCode.fromValue(codeAsInt);

  /// The number of bits of precision of a single scalar value of this type.
  @ffi.Uint8()
  external int bits;

  /// How many elements in a vector. This is 1 for scalar types.
  @ffi.Uint16()
  external int lanes;
}

typedef mnn_auto_time_t = ffi.Pointer<ffi.Void>;

final class mnn_backend_config_t extends ffi.Struct {
  /// mnn_memory_mode memory;
  @ffi.Int()
  external int memory;

  /// mnn_power_mode power;
  @ffi.Int()
  external int power;

  /// mnn_precision_mode precision;
  @ffi.Int()
  external int precision;

  external UnnamedUnion$1 unnamed;
}

typedef mnn_backend_t = ffi.Pointer<ffi.Void>;
typedef mnn_callback_0 = ffi.Pointer<ffi.NativeFunction<mnn_callback_0Function>>;
typedef mnn_callback_0Function = ffi.Void Function();
typedef Dartmnn_callback_0Function = void Function();
typedef mnn_cv_image_process_t = ffi.Pointer<ffi.Void>;
typedef mnn_cv_matrix_t = ffi.Pointer<ffi.Void>;

final class mnn_cv_point_t extends ffi.Struct {
  @ffi.Float()
  external double x;

  @ffi.Float()
  external double y;
}

final class mnn_cv_rect_t extends ffi.Struct {
  @ffi.Float()
  external double left;

  @ffi.Float()
  external double top;

  @ffi.Float()
  external double right;

  @ffi.Float()
  external double bottom;
}

typedef mnn_expr_Expr_t = ffi.Pointer<ffi.Void>;

final class mnn_expr_Variable_Info extends ffi.Struct {
  @ffi.Int()
  external int order;

  external ffi.Pointer<ffi.Int32> dim;

  @ffi.Size()
  external int ndim;

  external halide_type_c_t type;

  @ffi.Size()
  external int size;
}

/// Forward type enum */
/// // typedef mnn_forward_type mnn_forward_type_t;
typedef mnn_forward_type_t = ffi.Int;
typedef Dartmnn_forward_type_t = int;

final class mnn_image_process_config_t extends ffi.Struct {
  /// data filter
  @ffi.Int()
  external int filterType;

  /// format of source data
  @ffi.Int()
  external int sourceFormat;

  /// format of destination data
  @ffi.Int()
  external int destFormat;

  /// Only valid if the dest type is float
  @ffi.Array.multi([4])
  external ffi.Array<ffi.Float> mean;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Float> normal;

  /// edge wrapper
  @ffi.Int()
  external int wrap;
}

typedef mnn_interpreter_t = ffi.Pointer<ffi.Void>;

/// Config struct equivalent for C
final class mnn_module_config_t extends ffi.Struct {
  /// Load module as dynamic, default static
  @ffi.Bool()
  external bool dynamic;

  /// for static mode, if the shape is mutable, set true, otherwise set false to avoid resizeSession freqencily
  @ffi.Bool()
  external bool shape_mutable;

  /// Pre-rearrange weights or not. Disabled by default.
  /// The weights will be rearranged in a general way, so the best implementation
  /// may not be adopted if `rearrange` is enabled.
  @ffi.Bool()
  external bool rearrange;

  /// MNN_FORWARD_CPU
  @ffi.Int()
  external int backend_info_type;

  external ffi.Pointer<mnn_backend_config_t> backend_info_config;
}

typedef mnn_module_info_t = ffi.Pointer<ffi.Void>;

/// typedef void *mnn_executor_t;
typedef mnn_module_t = ffi.Pointer<ffi.Void>;
typedef mnn_runtime_info_t = ffi.Pointer<ffi.Void>;
typedef mnn_runtime_manager_t = ffi.Pointer<ffi.Void>;

/// Schedule config structure
final class mnn_schedule_config_t extends ffi.Struct {
  @mnn_forward_type_t()
  external int type;

  external UnnamedUnion unnamed;

  @mnn_forward_type_t()
  external int backupType;

  external ffi.Pointer<mnn_backend_config_t> backend_config;
}

typedef mnn_session_t = ffi.Pointer<ffi.Void>;

enum mnn_tensor_dtype {
  MNN_T_D_TYPE_F32_F64(0),
  MNN_T_D_TYPE_BF16(1),
  MNN_T_D_TYPE_QI32_I32_BOOL_I64(2),
  MNN_T_D_TYPE_QI8_I8(3),
  MNN_T_D_TYPE_QU8_U8(4),
  MNN_T_D_TYPE_QU16_U16(5),
  MNN_T_D_TYPE_QI16_I16(6)
  ;

  final int value;
  const mnn_tensor_dtype(this.value);

  static mnn_tensor_dtype fromValue(int value) => switch (value) {
    0 => MNN_T_D_TYPE_F32_F64,
    1 => MNN_T_D_TYPE_BF16,
    2 => MNN_T_D_TYPE_QI32_I32_BOOL_I64,
    3 => MNN_T_D_TYPE_QI8_I8,
    4 => MNN_T_D_TYPE_QU8_U8,
    5 => MNN_T_D_TYPE_QU16_U16,
    6 => MNN_T_D_TYPE_QI16_I16,
    _ => throw ArgumentError('Unknown value for mnn_tensor_dtype: $value'),
  };
}

typedef mnn_tensor_t = ffi.Pointer<ffi.Void>;
typedef mnn_timer_t = ffi.Pointer<ffi.Void>;

/// load image by filename, open file, or memory buffer
final class stbi_io_callbacks extends ffi.Struct {
  /// fill 'data' with 'size' bytes.  return number of bytes actually read
  external ffi.Pointer<
    ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Void> user, ffi.Pointer<ffi.Char> data, ffi.Int size)>
  >
  read;

  /// skip the next 'n' bytes, or 'unget' the last -n bytes if negative
  external ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void> user, ffi.Int n)>> skip;

  /// returns nonzero if we are at end of file/data
  external ffi.Pointer<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Void> user)>> eof;
}

typedef stbi_uc = ffi.UnsignedChar;
typedef Dartstbi_uc = int;
typedef stbi_us = ffi.UnsignedShort;
typedef Dartstbi_us = int;
typedef stbi_write_func =
    ffi.NativeFunction<
      ffi.Void Function(ffi.Pointer<ffi.Void> context, ffi.Pointer<ffi.Void> data, ffi.Int size)
    >;

final class stbir__info extends ffi.Opaque {}

/// callbacks for user installed filters
typedef stbir__kernel_callback =
    ffi.NativeFunction<ffi.Float Function(ffi.Float x, ffi.Float scale, ffi.Pointer<ffi.Void> user_data)>;
typedef stbir__support_callback =
    ffi.NativeFunction<ffi.Float Function(ffi.Float scale, ffi.Pointer<ffi.Void> user_data)>;

/// INPUT CALLBACK: this callback is used for input scanlines
typedef stbir_input_callback =
    ffi.NativeFunction<
      ffi.Pointer<ffi.Void> Function(
        ffi.Pointer<ffi.Void> optional_output,
        ffi.Pointer<ffi.Void> input_ptr,
        ffi.Int num_pixels,
        ffi.Int x,
        ffi.Int y,
        ffi.Pointer<ffi.Void> context,
      )
    >;

/// OUTPUT CALLBACK: this callback is used for output scanlines
typedef stbir_output_callback =
    ffi.NativeFunction<
      ffi.Void Function(
        ffi.Pointer<ffi.Void> output_ptr,
        ffi.Int num_pixels,
        ffi.Int y,
        ffi.Pointer<ffi.Void> context,
      )
    >;
typedef stbir_uint16 = ffi.Uint16;
typedef Dartstbir_uint16 = int;
typedef stbir_uint32 = ffi.Uint32;
typedef Dartstbir_uint32 = int;
typedef stbir_uint64 = ffi.Uint64;
typedef Dartstbir_uint64 = int;
typedef stbir_uint8 = ffi.Uint8;
typedef Dartstbir_uint8 = int;
typedef uchar = ffi.UnsignedChar;
typedef Dartuchar = int;
